{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Product Recommendations for Online Retail Store](https://medium.com/@peggy1502/product-recommendations-for-online-retail-store-1d565e1607b7)\n",
    "### Build and Train a Personalized Recommender Engine with Amazon Sagemaker Factorization Machines\n",
    "\n",
    "**This is `Notebook Part 2`**\n",
    "\n",
    "**Click [here](fm_v3_part1.ipynb) for `Notebook Part 1`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T06:55:14.595304Z",
     "iopub.status.busy": "2021-10-26T06:55:14.594728Z",
     "iopub.status.idle": "2021-10-26T06:55:15.918172Z",
     "shell.execute_reply": "2021-10-26T06:55:15.917462Z",
     "shell.execute_reply.started": "2021-10-26T06:55:14.595145Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "\n",
    "import boto3\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack, save_npz, load_npz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T06:55:15.920824Z",
     "iopub.status.busy": "2021-10-26T06:55:15.920256Z",
     "iopub.status.idle": "2021-10-26T06:55:15.927024Z",
     "shell.execute_reply": "2021-10-26T06:55:15.925926Z",
     "shell.execute_reply.started": "2021-10-26T06:55:15.920771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.19.5\n",
      "pandas version: 1.1.5\n",
      "boto3 version: 1.19.3\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"boto3 version:\", boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.63.2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T06:56:29.974833Z",
     "iopub.status.busy": "2021-10-26T06:56:29.974117Z",
     "iopub.status.idle": "2021-10-26T06:56:29.978912Z",
     "shell.execute_reply": "2021-10-26T06:56:29.978019Z",
     "shell.execute_reply.started": "2021-10-26T06:56:29.974790Z"
    }
   },
   "outputs": [],
   "source": [
    "# load array and sparse matrices.\n",
    "\n",
    "X_train = load_npz(\"X_train.npz\")\n",
    "X_test = load_npz(\"X_test.npz\")\n",
    "\n",
    "y_train = np.load(\"y_train.npz\")\n",
    "y_test = np.load(\"y_test.npz\")\n",
    "y_train = y_train.f.arr_0\n",
    "y_test = y_test.f.arr_0\n",
    "\n",
    "# Example of sparse matrix for X_test\n",
    "# pd.DataFrame(X_test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211030"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dim = 0\n",
    "\n",
    "# Read the saved feature dimension.\n",
    "with open(\"feature_dim.txt\", \"r\") as f:\n",
    "    feature_dim = int(f.read())\n",
    "    \n",
    "feature_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sparse RecordIO File\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html\n",
    "\n",
    "For **training**, the **Factorization Machines** algorithm currently supports only the `recordIO-protobuf` format with `Float32` tensors.\n",
    "\n",
    "For **inference**, the **Factorization Machines** algorithm supports the `application/json` and `x-recordio-protobuf` formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.132376Z",
     "iopub.status.idle": "2021-10-26T06:56:30.133061Z",
     "shell.execute_reply": "2021-10-26T06:56:30.132802Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.132774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create sparse RecordIO file.\n",
    "\n",
    "def write_sparse_recordio_file (filename, X, y=None):\n",
    "    with open(filename, 'wb') as f:\n",
    "        smac.write_spmatrix_to_sparse_tensor (f, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.134211Z",
     "iopub.status.idle": "2021-10-26T06:56:30.134959Z",
     "shell.execute_reply": "2021-10-26T06:56:30.134707Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.134675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to upload file to S3.\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.upload_fileobj\n",
    "\n",
    "def upload_to_s3(filename, bucket, prefix, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        boto3.Session().resource('s3').Bucket(bucket).Object(f\"{prefix}/{key}\").upload_fileobj(f)\n",
    "        return f\"s3://{bucket}/{prefix}/{key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.136780Z",
     "iopub.status.idle": "2021-10-26T06:56:30.137730Z",
     "shell.execute_reply": "2021-10-26T06:56:30.137454Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.137424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the train and test RecordIO files.\n",
    "\n",
    "write_sparse_recordio_file(\"fm_train.recordio\", X_train, y_train)\n",
    "write_sparse_recordio_file(\"fm_test.recordio\", X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.139216Z",
     "iopub.status.idle": "2021-10-26T06:56:30.139684Z",
     "shell.execute_reply": "2021-10-26T06:56:30.139446Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.139422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.63.2\n",
      "Region: us-east-2\n",
      "Bucket: sagemaker-us-east-2-802795124455\n",
      "train file location: s3://sagemaker-us-east-2-802795124455/fm/fm_train.recordio\n",
      "test file location: s3://sagemaker-us-east-2-802795124455/fm/fm_test.recordio\n",
      "model output location: s3://sagemaker-us-east-2-802795124455/fm/output\n"
     ]
    }
   ],
   "source": [
    "# Uploading the train and test RecordIO files to S3.\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "prefix = \"fm\"\n",
    "train_key = \"fm_train.recordio\"\n",
    "test_key = \"fm_test.recordio\"\n",
    "output_location = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "train_file_location = upload_to_s3(\"fm_train.recordio\", bucket, prefix, train_key)\n",
    "test_file_location = upload_to_s3(\"fm_test.recordio\", bucket, prefix, test_key)\n",
    "\n",
    "print(\"SageMaker version:\", sagemaker.__version__)\n",
    "print(\"Region:\", region)\n",
    "print(\"Bucket:\", bucket)\n",
    "print(\"train file location:\", train_file_location)\n",
    "print(\"test file location:\", test_file_location)\n",
    "print(\"model output location:\", output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Job & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.143448Z",
     "iopub.status.idle": "2021-10-26T06:56:30.144530Z",
     "shell.execute_reply": "2021-10-26T06:56:30.144264Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.144232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fm-ecommerce-v3-2021-10-30-02-20-41'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = 'fm-ecommerce-v3-' + \n",
    "            time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.140985Z",
     "iopub.status.idle": "2021-10-26T06:56:30.141441Z",
     "shell.execute_reply": "2021-10-26T06:56:30.141223Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.141200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint uri: None\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/aws-samples/amazon-sagemaker-managed-spot-training/blob/main/xgboost_built_in_managed_spot_training_checkpointing/xgboost_built_in_managed_spot_training_checkpointing.ipynb\n",
    "    \n",
    "use_spot_instances = False\n",
    "max_run = 3600                                   # set to 60 mins\n",
    "max_wait = 3600 if use_spot_instances else None  # set to 60 mins (must be equal or greater than max_run)\n",
    "   \n",
    "checkpoint_s3_uri = (f\"s3://{bucket}/{prefix}/checkpoints/{job_name}\" if use_spot_instances\n",
    "                     else None)\n",
    "    \n",
    "print(f\"Checkpoint uri: {checkpoint_s3_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.146118Z",
     "iopub.status.idle": "2021-10-26T06:56:30.146587Z",
     "shell.execute_reply": "2021-10-26T06:56:30.146367Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.146342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::802795124455:role/service-role/AmazonSageMaker-ExecutionRole-20211026T153321'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.147904Z",
     "iopub.status.idle": "2021-10-26T06:56:30.148349Z",
     "shell.execute_reply": "2021-10-26T06:56:30.148130Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.148106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'404615174143.dkr.ecr.us-east-2.amazonaws.com/factorization-machines:1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\", region=region)\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(    \n",
    "    container,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.m4.xlarge\",   # Or \"ml.c5.xlarge\",\n",
    "    output_path = output_location,\n",
    "    sagemaker_session = sess,\n",
    "    base_job_name = job_name,\n",
    "    use_spot_instances = use_spot_instances,\n",
    "    max_run = max_run,\n",
    "    max_wait = max_wait,\n",
    "    checkpoint_s3_uri = checkpoint_s3_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.149573Z",
     "iopub.status.idle": "2021-10-26T06:56:30.150082Z",
     "shell.execute_reply": "2021-10-26T06:56:30.149862Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.149836Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines-hyperparameters.html\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "    feature_dim = feature_dim,\n",
    "    num_factors = 64,  \n",
    "    predictor_type = \"regressor\",\n",
    "    epochs = 88,      \n",
    "    mini_batch_size = 1000,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.151897Z",
     "iopub.status.idle": "2021-10-26T06:56:30.152331Z",
     "shell.execute_reply": "2021-10-26T06:56:30.152122Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.152100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 211030,\n",
       " 'num_factors': 64,\n",
       " 'predictor_type': 'regressor',\n",
       " 'epochs': 88,\n",
       " 'mini_batch_size': 1000}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.153773Z",
     "iopub.status.idle": "2021-10-26T06:56:30.154253Z",
     "shell.execute_reply": "2021-10-26T06:56:30.154025Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.153999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-30 02:23:13 Starting - Starting the training job...\n",
      "2021-10-30 02:23:37 Starting - Launching requested ML instancesProfilerReport-1635560593: InProgress\n",
      "...\n",
      "2021-10-30 02:24:08 Starting - Preparing the instances for training.........\n",
      "2021-10-30 02:25:38 Downloading - Downloading input data...\n",
      "2021-10-30 02:25:58 Training - Downloading the training image...\n",
      "2021-10-30 02:26:38 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:87: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:120: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '211030', 'predictor_type': 'regressor', 'num_factors': '64', 'epochs': '88', 'mini_batch_size': '1000'}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] Final configuration: {'epochs': '88', 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '211030', 'predictor_type': 'regressor', 'num_factors': '64'}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 WARNING 140714915637056] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] Using default worker.\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:26:41.445] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:26:41.456] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 15, \"num_examples\": 1, \"num_bytes\": 104900}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:41 INFO 140714915637056] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560801.4404519, \"EndTime\": 1635560801.496145, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 44.57879066467285, \"count\": 1, \"min\": 44.57879066467285, \"max\": 44.57879066467285}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560801.4963062, \"EndTime\": 1635560801.4963422, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[02:26:41] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204642.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[02:26:41] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204642.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=98.98499886346416\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=9798.03\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=38.19621875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:26:47.730] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 5644, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=13.900733759005426\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=0, train mse <loss>=193.23039903875315\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=2.1660568688434103\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560801.496237, \"EndTime\": 1635560807.7315445, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 88.0, \"count\": 1, \"min\": 88, \"max\": 88}, \"update.time\": {\"sum\": 6234.86065864563, \"count\": 1, \"min\": 6234.86065864563, \"max\": 6234.86065864563}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:47 INFO 140714915637056] #progress_metric: host=algo-1, completed 1.1363636363636365 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560801.4966428, \"EndTime\": 1635560807.7318568, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 322421.0, \"count\": 1, \"min\": 322421, \"max\": 322421}, \"Total Batches Seen\": {\"sum\": 323.0, \"count\": 1, \"min\": 323, \"max\": 323}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:47 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=51548.10508073339 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=6.809679748802436\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=46.37173828125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=1.370604736328125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:26:52.805] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 5069, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=8.834326277883381\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=1, train mse <loss>=78.04532078410084\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=1.189023306141729\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560807.7316608, \"EndTime\": 1635560812.805964, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5072.132587432861, \"count\": 1, \"min\": 5072.132587432861, \"max\": 5072.132587432861}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:52 INFO 140714915637056] #progress_metric: host=algo-1, completed 2.272727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560807.733796, \"EndTime\": 1635560812.8062317, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 643842.0, \"count\": 1, \"min\": 643842, \"max\": 643842}, \"Total Batches Seen\": {\"sum\": 645.0, \"count\": 1, \"min\": 645, \"max\": 645}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:52 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63364.18964492127 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=6.7744626170641755\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=45.89334375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=1.357410888671875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:26:57.732] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 4921, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=8.957221549552862\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=2, train mse <loss>=80.23181788777417\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=1.258531308760554\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560812.8060586, \"EndTime\": 1635560817.733255, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4925.074577331543, \"count\": 1, \"min\": 4925.074577331543, \"max\": 4925.074577331543}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:57 INFO 140714915637056] #progress_metric: host=algo-1, completed 3.409090909090909 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560812.8081448, \"EndTime\": 1635560817.7336833, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 965263.0, \"count\": 1, \"min\": 965263, \"max\": 965263}, \"Total Batches Seen\": {\"sum\": 967.0, \"count\": 1, \"min\": 967, \"max\": 967}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:57 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65253.926912401075 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=6.7841128749454045\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=46.0241875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:26:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=1.38238623046875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:02.940] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 5202, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=8.924909946243446\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=3, train mse <loss>=79.65401754855517\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=1.2715451506620608\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560817.7334013, \"EndTime\": 1635560822.9410396, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5205.099582672119, \"count\": 1, \"min\": 5205.099582672119, \"max\": 5205.099582672119}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:02 INFO 140714915637056] #progress_metric: host=algo-1, completed 4.545454545454546 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560817.7359068, \"EndTime\": 1635560822.941357, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1286684.0, \"count\": 1, \"min\": 1286684, \"max\": 1286684}, \"Total Batches Seen\": {\"sum\": 1289.0, \"count\": 1, \"min\": 1289, \"max\": 1289}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:02 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=61745.38267788907 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=6.741541575374285\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=45.4483828125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=1.356604248046875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:08.539] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 5593, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=8.912539444830855\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=4, train mse <loss>=79.43335935566589\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=1.2448928575219576\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560822.941125, \"EndTime\": 1635560828.5398614, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5596.599578857422, \"count\": 1, \"min\": 5596.599578857422, \"max\": 5596.599578857422}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:08 INFO 140714915637056] #progress_metric: host=algo-1, completed 5.681818181818182 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560822.9432318, \"EndTime\": 1635560828.540105, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1608105.0, \"count\": 1, \"min\": 1608105, \"max\": 1608105}, \"Total Batches Seen\": {\"sum\": 1611.0, \"count\": 1, \"min\": 1611, \"max\": 1611}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:08 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=57427.45372700697 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=6.788392551812247\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=46.0822734375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=1.4742205810546876\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:13.736] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 5192, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=8.946835475723292\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=5, train mse <loss>=80.04586502966082\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=1.3143491061192862\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560828.5399513, \"EndTime\": 1635560833.7375553, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5195.528030395508, \"count\": 1, \"min\": 5195.528030395508, \"max\": 5195.528030395508}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:13 INFO 140714915637056] #progress_metric: host=algo-1, completed 6.818181818181818 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560828.5419972, \"EndTime\": 1635560833.7379036, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1929526.0, \"count\": 1, \"min\": 1929526, \"max\": 1929526}, \"Total Batches Seen\": {\"sum\": 1933.0, \"count\": 1, \"min\": 1933, \"max\": 1933}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:13 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=61858.814119624956 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=6.735923110921769\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=45.37266015625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=1.3330400390625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:18.790] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 5049, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=9.164550452847656\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=6, train mse <loss>=83.98898500279017\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=1.4710018867824388\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560833.737654, \"EndTime\": 1635560838.791651, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5051.616907119751, \"count\": 1, \"min\": 5051.616907119751, \"max\": 5051.616907119751}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:18 INFO 140714915637056] #progress_metric: host=algo-1, completed 7.954545454545454 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560833.7400038, \"EndTime\": 1635560838.7918842, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2250947.0, \"count\": 1, \"min\": 2250947, \"max\": 2250947}, \"Total Batches Seen\": {\"sum\": 2255.0, \"count\": 1, \"min\": 2255, \"max\": 2255}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:18 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63622.51014324035 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=7.029017979063648\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=49.40709375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=1.7972286376953126\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:27:23.650] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 4854, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=9.9512748800453\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=7, train mse <loss>=99.0278717382206\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=1.9195738822984398\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560838.7917287, \"EndTime\": 1635560843.6509855, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4857.171058654785, \"count\": 1, \"min\": 4857.171058654785, \"max\": 4857.171058654785}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:23 INFO 140714915637056] #progress_metric: host=algo-1, completed 9.090909090909092 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560838.7937844, \"EndTime\": 1635560843.6512284, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2572368.0, \"count\": 1, \"min\": 2572368, \"max\": 2572368}, \"Total Batches Seen\": {\"sum\": 2577.0, \"count\": 1, \"min\": 2577, \"max\": 2577}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:23 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66168.35322250478 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=8.052161734202189\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=64.83730859375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=2.329471923828125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:28.514] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 4859, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=9.436364015589813\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=8, train mse <loss>=89.04496583471831\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=1.78536572265625\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560843.6510715, \"EndTime\": 1635560848.515208, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4861.947536468506, \"count\": 1, \"min\": 4861.947536468506, \"max\": 4861.947536468506}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:28 INFO 140714915637056] #progress_metric: host=algo-1, completed 10.227272727272727 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560843.6532252, \"EndTime\": 1635560848.5155323, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2893789.0, \"count\": 1, \"min\": 2893789, \"max\": 2893789}, \"Total Batches Seen\": {\"sum\": 2899.0, \"count\": 1, \"min\": 2899, \"max\": 2899}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:28 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66102.42713790998 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=7.772486531027249\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=60.411546875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=2.42420703125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:33.366] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 4844, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=10.26224198085549\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=9, train mse <loss>=105.3136104736328\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=2.0972246774235126\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560848.515314, \"EndTime\": 1635560853.367536, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4849.231719970703, \"count\": 1, \"min\": 4849.231719970703, \"max\": 4849.231719970703}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:33 INFO 140714915637056] #progress_metric: host=algo-1, completed 11.363636363636363 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560848.5182438, \"EndTime\": 1635560853.367769, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3215210.0, \"count\": 1, \"min\": 3215210, \"max\": 3215210}, \"Total Batches Seen\": {\"sum\": 3221.0, \"count\": 1, \"min\": 3221, \"max\": 3221}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:33 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66276.96958025046 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=8.443275800896238\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=71.28890625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=2.79614892578125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:38.169] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 4798, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=9.571157512764428\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=10, train mse <loss>=91.60705613414693\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=1.8584120479607433\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560853.367616, \"EndTime\": 1635560858.170686, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4800.882339477539, \"count\": 1, \"min\": 4800.882339477539, \"max\": 4800.882339477539}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:38 INFO 140714915637056] #progress_metric: host=algo-1, completed 12.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560853.3697703, \"EndTime\": 1635560858.170972, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3536631.0, \"count\": 1, \"min\": 3536631, \"max\": 3536631}, \"Total Batches Seen\": {\"sum\": 3543.0, \"count\": 1, \"min\": 3543, \"max\": 3543}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:38 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66944.07819224916 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=9.009011547472896\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=81.1622890625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=2.874963134765625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:27:43.180] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 5005, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=10.130703596412047\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=11, train mse <loss>=102.63115535835598\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=2.1028308903474984\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560858.1707847, \"EndTime\": 1635560863.1811872, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5008.260011672974, \"count\": 1, \"min\": 5008.260011672974, \"max\": 5008.260011672974}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:43 INFO 140714915637056] #progress_metric: host=algo-1, completed 13.636363636363637 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560858.172897, \"EndTime\": 1635560863.181463, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3858052.0, \"count\": 1, \"min\": 3858052, \"max\": 3858052}, \"Total Batches Seen\": {\"sum\": 3865.0, \"count\": 1, \"min\": 3865, \"max\": 3865}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:43 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64172.644998452015 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=8.515336807049971\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=72.5109609375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=2.59493798828125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:48.044] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 4859, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:48 INFO 140714915637056] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=10.419924237509337\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:48 INFO 140714915637056] #quality_metric: host=algo-1, epoch=12, train mse <loss>=108.57482111543455\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:48 INFO 140714915637056] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=2.340028925925308\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560863.1812966, \"EndTime\": 1635560868.044928, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4861.428260803223, \"count\": 1, \"min\": 4861.428260803223, \"max\": 4861.428260803223}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:48 INFO 140714915637056] #progress_metric: host=algo-1, completed 14.772727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560863.183469, \"EndTime\": 1635560868.0451615, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4179473.0, \"count\": 1, \"min\": 4179473, \"max\": 4179473}, \"Total Batches Seen\": {\"sum\": 4187.0, \"count\": 1, \"min\": 4187, \"max\": 4187}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:48 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66111.3350497317 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:48 INFO 140714915637056] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=13.070635624368082\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:48 INFO 140714915637056] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=170.841515625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:48 INFO 140714915637056] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=5.0265078125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:52.916] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 4867, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=9.945730408071293\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=13, train mse <loss>=98.91755335003397\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=2.0376580863620926\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560868.045008, \"EndTime\": 1635560872.9173849, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4870.258092880249, \"count\": 1, \"min\": 4870.258092880249, \"max\": 4870.258092880249}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:52 INFO 140714915637056] #progress_metric: host=algo-1, completed 15.909090909090908 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560868.0470927, \"EndTime\": 1635560872.9176848, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4500894.0, \"count\": 1, \"min\": 4500894, \"max\": 4500894}, \"Total Batches Seen\": {\"sum\": 4509.0, \"count\": 1, \"min\": 4509, \"max\": 4509}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:52 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65990.17570952402 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=18.915895266944148\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=357.81109375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=6.966923828125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:27:57.801] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 4879, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=10.00329438472342\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=14, train mse <loss>=100.0658985474391\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=2.134003473317401\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560872.9174857, \"EndTime\": 1635560877.80164, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4882.030963897705, \"count\": 1, \"min\": 4882.030963897705, \"max\": 4882.030963897705}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:57 INFO 140714915637056] #progress_metric: host=algo-1, completed 17.045454545454547 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560872.9195786, \"EndTime\": 1635560877.8018694, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4822315.0, \"count\": 1, \"min\": 4822315, \"max\": 4822315}, \"Total Batches Seen\": {\"sum\": 4831.0, \"count\": 1, \"min\": 4831, \"max\": 4831}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:57 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65832.44361896413 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=9.245327789618928\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=85.4760859375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:27:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=3.367879638671875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:28:02.856] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 5050, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=11.265372992721643\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=15, train mse <loss>=126.90862866514217\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=2.5379479152134485\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560877.8017163, \"EndTime\": 1635560882.8568435, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5053.015232086182, \"count\": 1, \"min\": 5053.015232086182, \"max\": 5053.015232086182}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:02 INFO 140714915637056] #progress_metric: host=algo-1, completed 18.181818181818183 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560877.8037994, \"EndTime\": 1635560882.857124, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5143736.0, \"count\": 1, \"min\": 5143736, \"max\": 5143736}, \"Total Batches Seen\": {\"sum\": 5153.0, \"count\": 1, \"min\": 5153, \"max\": 5153}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:02 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63604.353018761656 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=28.825523629242195\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=830.9108125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=10.8956298828125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:08.439] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 5578, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=13.186541776584987\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=16, train mse <loss>=173.88488402562112\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=2.8420943146699704\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560882.8569179, \"EndTime\": 1635560888.4401157, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5581.048011779785, \"count\": 1, \"min\": 5581.048011779785, \"max\": 5581.048011779785}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:08 INFO 140714915637056] #progress_metric: host=algo-1, completed 19.318181818181817 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560882.8590376, \"EndTime\": 1635560888.4403517, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5465157.0, \"count\": 1, \"min\": 5465157, \"max\": 5465157}, \"Total Batches Seen\": {\"sum\": 5475.0, \"count\": 1, \"min\": 5475, \"max\": 5475}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:08 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=57587.53271471489 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=8.19578397714337\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=67.170875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=2.490301513671875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:13.478] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 5034, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=10.214823583518536\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=17, train mse <loss>=104.34262084240648\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=2.061856444364749\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560888.4401956, \"EndTime\": 1635560893.4791923, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5036.799907684326, \"count\": 1, \"min\": 5036.799907684326, \"max\": 5036.799907684326}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:13 INFO 140714915637056] #progress_metric: host=algo-1, completed 20.454545454545453 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560888.4423578, \"EndTime\": 1635560893.479479, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5786578.0, \"count\": 1, \"min\": 5786578, \"max\": 5786578}, \"Total Batches Seen\": {\"sum\": 5797.0, \"count\": 1, \"min\": 5797, \"max\": 5797}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:13 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63808.660640486574 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=14.507622996204443\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=210.471125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=5.51053125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:18.384] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 4900, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=9.76896730327817\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=18, train mse <loss>=95.43272217251796\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=1.8433464065456984\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560893.4792874, \"EndTime\": 1635560898.38552, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4904.0374755859375, \"count\": 1, \"min\": 4904.0374755859375, \"max\": 4904.0374755859375}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:18 INFO 140714915637056] #progress_metric: host=algo-1, completed 21.59090909090909 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560893.4814281, \"EndTime\": 1635560898.386012, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6107999.0, \"count\": 1, \"min\": 6107999, \"max\": 6107999}, \"Total Batches Seen\": {\"sum\": 6119.0, \"count\": 1, \"min\": 6119, \"max\": 6119}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:18 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65532.623170012994 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=6.956192722136154\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=48.3886171875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=1.589541015625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:28:23.262] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 4872, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=12.134095292723076\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=19, train mse <loss>=147.2362685728843\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=3.0316840162573393\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560898.3856108, \"EndTime\": 1635560903.2631388, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4875.050783157349, \"count\": 1, \"min\": 4875.050783157349, \"max\": 4875.050783157349}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:23 INFO 140714915637056] #progress_metric: host=algo-1, completed 22.727272727272727 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560898.3880582, \"EndTime\": 1635560903.2633717, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6429420.0, \"count\": 1, \"min\": 6429420, \"max\": 6429420}, \"Total Batches Seen\": {\"sum\": 6441.0, \"count\": 1, \"min\": 6441, \"max\": 6441}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:23 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65926.61892448846 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=23.854795115447963\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=569.05125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=8.699345703125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:28.122] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 4855, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=11.075642082595559\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=20, train mse <loss>=122.6698475417617\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=2.397228632956558\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560903.2632153, \"EndTime\": 1635560908.123157, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4857.760906219482, \"count\": 1, \"min\": 4857.760906219482, \"max\": 4857.760906219482}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:28 INFO 140714915637056] #progress_metric: host=algo-1, completed 23.863636363636363 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560903.265365, \"EndTime\": 1635560908.1234128, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6750841.0, \"count\": 1, \"min\": 6750841, \"max\": 6750841}, \"Total Batches Seen\": {\"sum\": 6763.0, \"count\": 1, \"min\": 6763, \"max\": 6763}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:28 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66160.82932019806 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=8.729957849984157\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=76.2121640625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=2.7423740234375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:33.047] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 4920, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=10.174418378388273\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=21, train mse <loss>=103.51878933848505\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=2.119290762575517\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560908.1232371, \"EndTime\": 1635560913.047923, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4922.476768493652, \"count\": 1, \"min\": 4922.476768493652, \"max\": 4922.476768493652}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:33 INFO 140714915637056] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560908.1254165, \"EndTime\": 1635560913.0481508, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7072262.0, \"count\": 1, \"min\": 7072262, \"max\": 7072262}, \"Total Batches Seen\": {\"sum\": 7085.0, \"count\": 1, \"min\": 7085, \"max\": 7085}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:33 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65291.57568229645 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=11.665613866188098\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=136.086546875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:33 INFO 140714915637056] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=4.46689697265625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:38.062] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 5010, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=10.986932025577921\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=22, train mse <loss>=120.71267533466978\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=2.4977999900675707\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560913.0479994, \"EndTime\": 1635560918.0627136, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5012.4921798706055, \"count\": 1, \"min\": 5012.4921798706055, \"max\": 5012.4921798706055}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:38 INFO 140714915637056] #progress_metric: host=algo-1, completed 26.136363636363637 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560913.0501912, \"EndTime\": 1635560918.0629573, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7393683.0, \"count\": 1, \"min\": 7393683, \"max\": 7393683}, \"Total Batches Seen\": {\"sum\": 7407.0, \"count\": 1, \"min\": 7407, \"max\": 7407}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:38 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64118.711114288184 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=8.619654140393337\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=74.2984375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:38 INFO 140714915637056] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=2.67912255859375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:28:43.069] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 5002, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=12.552742914486398\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=23, train mse <loss>=157.57135467718848\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=3.040632068326014\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560918.0627935, \"EndTime\": 1635560923.0704195, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5005.43999671936, \"count\": 1, \"min\": 5005.43999671936, \"max\": 5005.43999671936}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:43 INFO 140714915637056] #progress_metric: host=algo-1, completed 27.272727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560918.0649476, \"EndTime\": 1635560923.070691, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 7715104.0, \"count\": 1, \"min\": 7715104, \"max\": 7715104}, \"Total Batches Seen\": {\"sum\": 7729.0, \"count\": 1, \"min\": 7729, \"max\": 7729}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:43 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64208.8083404267 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=23.645020617457707\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=559.087\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:43 INFO 140714915637056] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=8.6405400390625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:47.946] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 4873, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=15.522258996955644\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=24, train mse <loss>=240.94052436857046\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=3.5175281768230175\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560923.0704982, \"EndTime\": 1635560927.9472585, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4876.233816146851, \"count\": 1, \"min\": 4876.233816146851, \"max\": 4876.233816146851}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:47 INFO 140714915637056] #progress_metric: host=algo-1, completed 28.40909090909091 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560923.0709903, \"EndTime\": 1635560927.9475536, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8036525.0, \"count\": 1, \"min\": 8036525, \"max\": 8036525}, \"Total Batches Seen\": {\"sum\": 8051.0, \"count\": 1, \"min\": 8051, \"max\": 8051}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:47 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65908.76633582501 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=6.739251569629227\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=45.41751171875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=1.3194852294921875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:52.734] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 4783, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=10.111007274676554\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=25, train mse <loss>=102.2324681085622\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=2.0592392911733306\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560927.9473639, \"EndTime\": 1635560932.7352273, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4785.63928604126, \"count\": 1, \"min\": 4785.63928604126, \"max\": 4785.63928604126}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:52 INFO 140714915637056] #progress_metric: host=algo-1, completed 29.545454545454547 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560927.9495578, \"EndTime\": 1635560932.7355945, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8357946.0, \"count\": 1, \"min\": 8357946, \"max\": 8357946}, \"Total Batches Seen\": {\"sum\": 8373.0, \"count\": 1, \"min\": 8373, \"max\": 8373}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:52 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=67155.56310871273 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=7.706517128379071\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=59.39040625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=2.046178466796875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:28:57.621] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 4881, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=10.33333476822398\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=26, train mse <loss>=106.77780743218653\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=2.2795415564116484\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560932.7353623, \"EndTime\": 1635560937.6220012, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4884.335517883301, \"count\": 1, \"min\": 4884.335517883301, \"max\": 4884.335517883301}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:57 INFO 140714915637056] #progress_metric: host=algo-1, completed 30.681818181818183 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560932.7376351, \"EndTime\": 1635560937.6222897, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8679367.0, \"count\": 1, \"min\": 8679367, \"max\": 8679367}, \"Total Batches Seen\": {\"sum\": 8695.0, \"count\": 1, \"min\": 8695, \"max\": 8695}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:57 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65800.18987296733 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=7.724762840210695\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=59.6719609375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:28:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=2.400224853515625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:29:02.784] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 5158, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=11.203070374224158\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=27, train mse <loss>=125.508785809819\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=2.7678026763726464\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560937.6220922, \"EndTime\": 1635560942.7854338, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5161.154985427856, \"count\": 1, \"min\": 5161.154985427856, \"max\": 5161.154985427856}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:02 INFO 140714915637056] #progress_metric: host=algo-1, completed 31.818181818181817 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560937.6242447, \"EndTime\": 1635560942.7857194, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9000788.0, \"count\": 1, \"min\": 9000788, \"max\": 9000788}, \"Total Batches Seen\": {\"sum\": 9017.0, \"count\": 1, \"min\": 9017, \"max\": 9017}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:02 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=62271.15539208631 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=13.885109492726372\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=192.796265625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=5.1453427734375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:08.403] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 5614, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=13.396568463000177\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=28, train mse <loss>=179.46804658385093\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=3.650188386336617\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560942.7855213, \"EndTime\": 1635560948.4045868, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5616.8372631073, \"count\": 1, \"min\": 5616.8372631073, \"max\": 5616.8372631073}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:08 INFO 140714915637056] #progress_metric: host=algo-1, completed 32.95454545454545 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560942.7877138, \"EndTime\": 1635560948.404979, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9322209.0, \"count\": 1, \"min\": 9322209, \"max\": 9322209}, \"Total Batches Seen\": {\"sum\": 9339.0, \"count\": 1, \"min\": 9339, \"max\": 9339}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:08 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=57218.71879988752 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=7.949878880759757\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=63.20057421875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=2.379597412109375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:13.418] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 5008, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=10.339224128123059\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=29, train mse <loss>=106.89955557156202\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=2.2811370186183764\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560948.4046848, \"EndTime\": 1635560953.4191554, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5012.0689868927, \"count\": 1, \"min\": 5012.0689868927, \"max\": 5012.0689868927}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:13 INFO 140714915637056] #progress_metric: host=algo-1, completed 34.09090909090909 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560948.4070332, \"EndTime\": 1635560953.4195504, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9643630.0, \"count\": 1, \"min\": 9643630, \"max\": 9643630}, \"Total Batches Seen\": {\"sum\": 9661.0, \"count\": 1, \"min\": 9661, \"max\": 9661}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:13 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64121.66626209448 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=7.397613371469882\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=54.72468359375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=1.875780517578125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:18.221] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 4798, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=13.28140602655428\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=30, train mse <loss>=176.39574604219234\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=3.7465874853667267\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560953.4192412, \"EndTime\": 1635560958.2221568, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4800.432443618774, \"count\": 1, \"min\": 4800.432443618774, \"max\": 4800.432443618774}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:18 INFO 140714915637056] #progress_metric: host=algo-1, completed 35.22727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560953.4216933, \"EndTime\": 1635560958.2223933, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 30, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9965051.0, \"count\": 1, \"min\": 9965051, \"max\": 9965051}, \"Total Batches Seen\": {\"sum\": 9983.0, \"count\": 1, \"min\": 9983, \"max\": 9983}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 32.0, \"count\": 1, \"min\": 32, \"max\": 32}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:18 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66951.23933502939 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=18.74260270746835\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=351.28515625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=6.9190869140625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:29:23.084] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 4858, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=12.183117211738773\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=31, train mse <loss>=148.42834499496556\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=3.2671403410538384\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560958.2222366, \"EndTime\": 1635560963.0849817, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4860.531806945801, \"count\": 1, \"min\": 4860.531806945801, \"max\": 4860.531806945801}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:23 INFO 140714915637056] #progress_metric: host=algo-1, completed 36.36363636363637 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560958.2244158, \"EndTime\": 1635560963.085311, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 31, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10286472.0, \"count\": 1, \"min\": 10286472, \"max\": 10286472}, \"Total Batches Seen\": {\"sum\": 10305.0, \"count\": 1, \"min\": 10305, \"max\": 10305}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:23 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66121.84415551292 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=13.01304573783555\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=169.339359375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:23 INFO 140714915637056] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=4.91682861328125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:27.998] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 4908, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=11.029050748905071\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=32, train mse <loss>=121.63996042192352\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=2.7382955269191576\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560963.0850797, \"EndTime\": 1635560967.9987876, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4911.436557769775, \"count\": 1, \"min\": 4911.436557769775, \"max\": 4911.436557769775}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:27 INFO 140714915637056] #progress_metric: host=algo-1, completed 37.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560963.087319, \"EndTime\": 1635560967.999087, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 32, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10607893.0, \"count\": 1, \"min\": 10607893, \"max\": 10607893}, \"Total Batches Seen\": {\"sum\": 10627.0, \"count\": 1, \"min\": 10627, \"max\": 10627}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 34.0, \"count\": 1, \"min\": 34, \"max\": 34}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:27 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65436.86308930799 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=7.614057209366107\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=57.9738671875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:28 INFO 140714915637056] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=2.3440263671875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:32.843] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 4840, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=13.377228287548363\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=33, train mse <loss>=178.9502366571841\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=3.796252250718774\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560967.9988816, \"EndTime\": 1635560972.844699, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4843.33872795105, \"count\": 1, \"min\": 4843.33872795105, \"max\": 4843.33872795105}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:32 INFO 140714915637056] #progress_metric: host=algo-1, completed 38.63636363636363 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560968.001325, \"EndTime\": 1635560972.8450189, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 33, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10929314.0, \"count\": 1, \"min\": 10929314, \"max\": 10929314}, \"Total Batches Seen\": {\"sum\": 10949.0, \"count\": 1, \"min\": 10949, \"max\": 10949}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 35.0, \"count\": 1, \"min\": 35, \"max\": 35}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:32 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66356.05808122856 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=18.563087532789368\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=344.58821875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=6.87138818359375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:37.782] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 4933, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=15.325847550472231\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=34, train mse <loss>=234.88160314031566\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=4.265997245646411\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560972.8447955, \"EndTime\": 1635560977.7833664, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4936.173915863037, \"count\": 1, \"min\": 4936.173915863037, \"max\": 4936.173915863037}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:37 INFO 140714915637056] #progress_metric: host=algo-1, completed 39.77272727272727 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560972.8471587, \"EndTime\": 1635560977.7836795, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 34, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11250735.0, \"count\": 1, \"min\": 11250735, \"max\": 11250735}, \"Total Batches Seen\": {\"sum\": 11271.0, \"count\": 1, \"min\": 11271, \"max\": 11271}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 36.0, \"count\": 1, \"min\": 36, \"max\": 36}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:37 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65108.84606640174 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=9.7375324935273\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=94.8195390625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=3.53174658203125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:29:42.818] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 5030, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=9.927660764122377\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=35, train mse <loss>=98.55844824749491\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=2.1036962871669984\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560977.7834704, \"EndTime\": 1635560982.8198469, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5034.049987792969, \"count\": 1, \"min\": 5034.049987792969, \"max\": 5034.049987792969}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:42 INFO 140714915637056] #progress_metric: host=algo-1, completed 40.90909090909091 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560977.7857661, \"EndTime\": 1635560982.8202763, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 35, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11572156.0, \"count\": 1, \"min\": 11572156, \"max\": 11572156}, \"Total Batches Seen\": {\"sum\": 11593.0, \"count\": 1, \"min\": 11593, \"max\": 11593}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:42 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63841.7028230074 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=6.688534674631656\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=44.73649609375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=1.3499122314453125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:47.683] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 4861, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=9.765810224252746\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=36, train mse <loss>=95.37104933611947\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=1.9198212376944026\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560982.8199222, \"EndTime\": 1635560987.6843123, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4863.700151443481, \"count\": 1, \"min\": 4863.700151443481, \"max\": 4863.700151443481}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:47 INFO 140714915637056] #progress_metric: host=algo-1, completed 42.04545454545455 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560982.8205807, \"EndTime\": 1635560987.6846232, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 36, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 11893577.0, \"count\": 1, \"min\": 11893577, \"max\": 11893577}, \"Total Batches Seen\": {\"sum\": 11915.0, \"count\": 1, \"min\": 11915, \"max\": 11915}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:47 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66078.92411260956 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=7.40220775765582\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=54.7926796875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=1.881130615234375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:52.674] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 4985, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=11.522423192081936\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=37, train mse <loss>=132.7662362174277\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=2.971191630677407\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560987.684416, \"EndTime\": 1635560992.675015, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4988.352537155151, \"count\": 1, \"min\": 4988.352537155151, \"max\": 4988.352537155151}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:52 INFO 140714915637056] #progress_metric: host=algo-1, completed 43.18181818181818 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560987.6866322, \"EndTime\": 1635560992.675298, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 37, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12214998.0, \"count\": 1, \"min\": 12214998, \"max\": 12214998}, \"Total Batches Seen\": {\"sum\": 12237.0, \"count\": 1, \"min\": 12237, \"max\": 12237}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 39.0, \"count\": 1, \"min\": 39, \"max\": 39}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:52 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64428.4638304018 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=9.667669622897753\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=93.4638359375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=3.222869384765625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:29:57.523] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 4844, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=14.961460223453\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=38, train mse <loss>=223.84529201796633\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=4.406586449664572\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560992.6750946, \"EndTime\": 1635560997.524335, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4846.930027008057, \"count\": 1, \"min\": 4846.930027008057, \"max\": 4846.930027008057}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:57 INFO 140714915637056] #progress_metric: host=algo-1, completed 44.31818181818182 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560992.677374, \"EndTime\": 1635560997.524581, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 38, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12536419.0, \"count\": 1, \"min\": 12536419, \"max\": 12536419}, \"Total Batches Seen\": {\"sum\": 12559.0, \"count\": 1, \"min\": 12559, \"max\": 12559}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 40.0, \"count\": 1, \"min\": 40, \"max\": 40}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:57 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66308.87391777043 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=18.75720944730319\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=351.83290625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:29:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=6.8189228515625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:30:02.572] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 5044, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=17.923269406374637\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=39, train mse <loss>=321.24358621348506\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=5.163884958587078\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560997.5244153, \"EndTime\": 1635561002.5735776, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5046.928882598877, \"count\": 1, \"min\": 5046.928882598877, \"max\": 5046.928882598877}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:02 INFO 140714915637056] #progress_metric: host=algo-1, completed 45.45454545454545 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635560997.5266168, \"EndTime\": 1635561002.573838, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 39, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12857840.0, \"count\": 1, \"min\": 12857840, \"max\": 12857840}, \"Total Batches Seen\": {\"sum\": 12881.0, \"count\": 1, \"min\": 12881, \"max\": 12881}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 41.0, \"count\": 1, \"min\": 41, \"max\": 41}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:02 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63681.05025160426 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=6.943572792518272\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=48.213203125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=1.6353609619140625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:08.160] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 5582, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=10.115551351549822\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=40, train mse <loss>=102.32437914584142\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=2.2613452273540617\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561002.573664, \"EndTime\": 1635561008.1609747, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5584.975957870483, \"count\": 1, \"min\": 5584.975957870483, \"max\": 5584.975957870483}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:08 INFO 140714915637056] #progress_metric: host=algo-1, completed 46.59090909090909 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561002.5759676, \"EndTime\": 1635561008.1612175, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 40, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13179261.0, \"count\": 1, \"min\": 13179261, \"max\": 13179261}, \"Total Batches Seen\": {\"sum\": 13203.0, \"count\": 1, \"min\": 13203, \"max\": 13203}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 42.0, \"count\": 1, \"min\": 42, \"max\": 42}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:08 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=57546.61626802551 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=6.762545632932912\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=45.7320234375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:08 INFO 140714915637056] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=1.4852052001953124\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:13.138] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 4973, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=9.69781054843572\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=41, train mse <loss>=94.04752943335113\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=1.9694826957750025\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561008.16106, \"EndTime\": 1635561013.1400063, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4976.675510406494, \"count\": 1, \"min\": 4976.675510406494, \"max\": 4976.675510406494}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:13 INFO 140714915637056] #progress_metric: host=algo-1, completed 47.72727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561008.1632986, \"EndTime\": 1635561013.1404617, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 41, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13500682.0, \"count\": 1, \"min\": 13500682, \"max\": 13500682}, \"Total Batches Seen\": {\"sum\": 13525.0, \"count\": 1, \"min\": 13525, \"max\": 13525}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:13 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64576.763575940786 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=13.826095119374813\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=191.16090625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:13 INFO 140714915637056] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=5.0785478515625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:18.045] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 4899, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=18.719425608617936\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=42, train mse <loss>=350.4168951165809\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=5.607952441861171\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561013.140177, \"EndTime\": 1635561018.0458279, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4902.382612228394, \"count\": 1, \"min\": 4902.382612228394, \"max\": 4902.382612228394}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:18 INFO 140714915637056] #progress_metric: host=algo-1, completed 48.86363636363637 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561013.1434126, \"EndTime\": 1635561018.04606, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 42, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13822103.0, \"count\": 1, \"min\": 13822103, \"max\": 13822103}, \"Total Batches Seen\": {\"sum\": 13847.0, \"count\": 1, \"min\": 13847, \"max\": 13847}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 44.0, \"count\": 1, \"min\": 44, \"max\": 44}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:18 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65558.93341933581 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=9.896865428634461\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=97.9479453125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:18 INFO 140714915637056] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=3.5201181640625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:22.938] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 4888, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=9.455232297659537\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=43, train mse <loss>=89.40141780270405\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=1.834442789776725\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561018.0459073, \"EndTime\": 1635561022.9393444, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4891.231536865234, \"count\": 1, \"min\": 4891.231536865234, \"max\": 4891.231536865234}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:22 INFO 140714915637056] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561018.0480845, \"EndTime\": 1635561022.9396281, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 43, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14143524.0, \"count\": 1, \"min\": 14143524, \"max\": 14143524}, \"Total Batches Seen\": {\"sum\": 14169.0, \"count\": 1, \"min\": 14169, \"max\": 14169}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:22 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65707.53767448557 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=6.834427440356653\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=46.7093984375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=1.409882080078125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:30:27.734] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 4791, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=9.384211569953916\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=44, train mse <loss>=88.06342678965693\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=1.7395511015897953\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561022.9394329, \"EndTime\": 1635561027.7351327, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4793.4889793396, \"count\": 1, \"min\": 4793.4889793396, \"max\": 4793.4889793396}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:27 INFO 140714915637056] #progress_metric: host=algo-1, completed 51.13636363636363 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561022.9416096, \"EndTime\": 1635561027.7354183, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 44, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14464945.0, \"count\": 1, \"min\": 14464945, \"max\": 14464945}, \"Total Batches Seen\": {\"sum\": 14491.0, \"count\": 1, \"min\": 14491, \"max\": 14491}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 46.0, \"count\": 1, \"min\": 46, \"max\": 46}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:27 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=67047.22463390252 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=11.216462162264\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=125.8090234375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=4.1733193359375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:32.602] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 4862, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=16.555090275722684\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=45, train mse <loss>=274.07101403732776\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=4.963458162864543\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561027.7352366, \"EndTime\": 1635561032.6029284, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4865.404844284058, \"count\": 1, \"min\": 4865.404844284058, \"max\": 4865.404844284058}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:32 INFO 140714915637056] #progress_metric: host=algo-1, completed 52.27272727272727 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561027.7374928, \"EndTime\": 1635561032.6031718, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 45, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 14786366.0, \"count\": 1, \"min\": 14786366, \"max\": 14786366}, \"Total Batches Seen\": {\"sum\": 14813.0, \"count\": 1, \"min\": 14813, \"max\": 14813}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 47.0, \"count\": 1, \"min\": 47, \"max\": 47}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:32 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66057.18881728523 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=9.509093509635921\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=90.422859375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=3.046724609375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:37.507] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 4900, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=11.57565202401804\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=46, train mse <loss>=133.99571978115296\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=2.978242045716469\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561032.603008, \"EndTime\": 1635561037.5086977, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4903.353452682495, \"count\": 1, \"min\": 4903.353452682495, \"max\": 4903.353452682495}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:37 INFO 140714915637056] #progress_metric: host=algo-1, completed 53.40909090909091 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561032.6052606, \"EndTime\": 1635561037.508991, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 46, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15107787.0, \"count\": 1, \"min\": 15107787, \"max\": 15107787}, \"Total Batches Seen\": {\"sum\": 15135.0, \"count\": 1, \"min\": 15135, \"max\": 15135}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:37 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65544.26195780109 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=7.083192584385942\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=50.1716171875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:37 INFO 140714915637056] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=1.687871337890625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:42.374] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 4861, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=10.09982179498938\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=47, train mse <loss>=102.0064002905425\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=2.1831673443717245\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561037.5087855, \"EndTime\": 1635561042.374795, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4863.753318786621, \"count\": 1, \"min\": 4863.753318786621, \"max\": 4863.753318786621}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:42 INFO 140714915637056] #progress_metric: host=algo-1, completed 54.54545454545455 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561037.5110087, \"EndTime\": 1635561042.3750622, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 47, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15429208.0, \"count\": 1, \"min\": 15429208, \"max\": 15429208}, \"Total Batches Seen\": {\"sum\": 15457.0, \"count\": 1, \"min\": 15457, \"max\": 15457}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 49.0, \"count\": 1, \"min\": 49, \"max\": 49}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:42 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66079.38727240716 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=11.331177950681031\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=128.39559375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:42 INFO 140714915637056] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=4.14683740234375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:30:47.405] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 5028, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=16.46994906658548\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=48, train mse <loss>=271.25922225592\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=4.976497008140043\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561042.3748977, \"EndTime\": 1635561047.4066267, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5031.242370605469, \"count\": 1, \"min\": 5031.242370605469, \"max\": 5031.242370605469}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:47 INFO 140714915637056] #progress_metric: host=algo-1, completed 55.68181818181818 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561042.3753486, \"EndTime\": 1635561047.4069088, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 48, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15750629.0, \"count\": 1, \"min\": 15750629, \"max\": 15750629}, \"Total Batches Seen\": {\"sum\": 15779.0, \"count\": 1, \"min\": 15779, \"max\": 15779}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 50.0, \"count\": 1, \"min\": 50, \"max\": 50}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:47 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63878.94079911708 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=7.718052600073415\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=59.5683359375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:47 INFO 140714915637056] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=2.206465576171875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:52.212] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 4801, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=12.074114099494288\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=49, train mse <loss>=145.78423128760676\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=3.2872834749399504\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561047.4067218, \"EndTime\": 1635561052.2136202, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4804.637908935547, \"count\": 1, \"min\": 4804.637908935547, \"max\": 4804.637908935547}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:52 INFO 140714915637056] #progress_metric: host=algo-1, completed 56.81818181818182 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561047.408952, \"EndTime\": 1635561052.2138624, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 49, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16072050.0, \"count\": 1, \"min\": 16072050, \"max\": 16072050}, \"Total Batches Seen\": {\"sum\": 16101.0, \"count\": 1, \"min\": 16101, \"max\": 16101}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 51.0, \"count\": 1, \"min\": 51, \"max\": 51}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:52 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66892.55916877495 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=12.941586311190758\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=50, batch=0 train mse <loss>=167.48465625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:52 INFO 140714915637056] #quality_metric: host=algo-1, epoch=50, batch=0 train absolute_loss <loss>=4.9366806640625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:30:57.139] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 4921, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=10.98515055936392\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=50, train mse <loss>=120.67353281189344\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=50, train absolute_loss <loss>=2.7149072477921194\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561052.2137074, \"EndTime\": 1635561057.1403193, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4924.3574142456055, \"count\": 1, \"min\": 4924.3574142456055, \"max\": 4924.3574142456055}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:57 INFO 140714915637056] #progress_metric: host=algo-1, completed 57.95454545454545 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561052.2159274, \"EndTime\": 1635561057.140619, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 50, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16393471.0, \"count\": 1, \"min\": 16393471, \"max\": 16393471}, \"Total Batches Seen\": {\"sum\": 16423.0, \"count\": 1, \"min\": 16423, \"max\": 16423}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 52.0, \"count\": 1, \"min\": 52, \"max\": 52}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:57 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65265.31208715304 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=6.774032737686614\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=51, batch=0 train mse <loss>=45.88751953125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:30:57 INFO 140714915637056] #quality_metric: host=algo-1, epoch=51, batch=0 train absolute_loss <loss>=1.4704239501953125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:02.046] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 4902, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=14.31142533638911\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=51, train mse <loss>=204.81689515904017\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=51, train absolute_loss <loss>=4.0596044565520675\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561057.1404214, \"EndTime\": 1635561062.047409, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4904.6924114227295, \"count\": 1, \"min\": 4904.6924114227295, \"max\": 4904.6924114227295}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:02 INFO 140714915637056] #progress_metric: host=algo-1, completed 59.09090909090909 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561057.1426811, \"EndTime\": 1635561062.0477068, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 51, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 16714892.0, \"count\": 1, \"min\": 16714892, \"max\": 16714892}, \"Total Batches Seen\": {\"sum\": 16745.0, \"count\": 1, \"min\": 16745, \"max\": 16745}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 53.0, \"count\": 1, \"min\": 53, \"max\": 53}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:02 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65526.96298186512 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=14.488643721032\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=52, batch=0 train mse <loss>=209.920796875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:02 INFO 140714915637056] #quality_metric: host=algo-1, epoch=52, batch=0 train absolute_loss <loss>=5.3141494140625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:31:07.572] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 5520, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:07 INFO 140714915637056] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=14.23771051649557\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:07 INFO 140714915637056] #quality_metric: host=algo-1, epoch=52, train mse <loss>=202.71240075152852\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:07 INFO 140714915637056] #quality_metric: host=algo-1, epoch=52, train absolute_loss <loss>=4.229147434779576\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561062.0475028, \"EndTime\": 1635561067.5729647, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5522.932291030884, \"count\": 1, \"min\": 5522.932291030884, \"max\": 5522.932291030884}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:07 INFO 140714915637056] #progress_metric: host=algo-1, completed 60.22727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561062.0500042, \"EndTime\": 1635561067.5732188, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 52, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17036313.0, \"count\": 1, \"min\": 17036313, \"max\": 17036313}, \"Total Batches Seen\": {\"sum\": 17067.0, \"count\": 1, \"min\": 17067, \"max\": 17067}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:07 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=58192.88439957258 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:07 INFO 140714915637056] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=10.105168850642723\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:07 INFO 140714915637056] #quality_metric: host=algo-1, epoch=53, batch=0 train mse <loss>=102.1144375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:07 INFO 140714915637056] #quality_metric: host=algo-1, epoch=53, batch=0 train absolute_loss <loss>=3.45558837890625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:12.531] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 4954, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=14.363887473994007\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=53, train mse <loss>=206.32126336556192\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=53, train absolute_loss <loss>=4.0901010203865\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561067.573065, \"EndTime\": 1635561072.5325217, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4957.036256790161, \"count\": 1, \"min\": 4957.036256790161, \"max\": 4957.036256790161}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:12 INFO 140714915637056] #progress_metric: host=algo-1, completed 61.36363636363637 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561067.5754542, \"EndTime\": 1635561072.5328004, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 53, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17357734.0, \"count\": 1, \"min\": 17357734, \"max\": 17357734}, \"Total Batches Seen\": {\"sum\": 17389.0, \"count\": 1, \"min\": 17389, \"max\": 17389}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:12 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64835.07267997173 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=10.61585488785524\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=54, batch=0 train mse <loss>=112.696375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=54, batch=0 train absolute_loss <loss>=3.8205234375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:17.511] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 4975, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=17.717618570150336\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=54, train mse <loss>=313.914007797336\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=54, train absolute_loss <loss>=5.481054829662631\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561072.532609, \"EndTime\": 1635561077.512517, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4977.683305740356, \"count\": 1, \"min\": 4977.683305740356, \"max\": 4977.683305740356}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:17 INFO 140714915637056] #progress_metric: host=algo-1, completed 62.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561072.5347993, \"EndTime\": 1635561077.5128055, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 54, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17679155.0, \"count\": 1, \"min\": 17679155, \"max\": 17679155}, \"Total Batches Seen\": {\"sum\": 17711.0, \"count\": 1, \"min\": 17711, \"max\": 17711}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 56.0, \"count\": 1, \"min\": 56, \"max\": 56}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:17 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64566.33783259291 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=15.56415955006887\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=55, batch=0 train mse <loss>=242.2430625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=55, batch=0 train absolute_loss <loss>=5.94708251953125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:22.352] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 4835, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=13.57540576820448\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=55, train mse <loss>=184.29164177139947\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=55, train absolute_loss <loss>=3.9952851960555367\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561077.5126188, \"EndTime\": 1635561082.3530831, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4838.230848312378, \"count\": 1, \"min\": 4838.230848312378, \"max\": 4838.230848312378}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:22 INFO 140714915637056] #progress_metric: host=algo-1, completed 63.63636363636363 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561077.5148225, \"EndTime\": 1635561082.3533437, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 55, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18000576.0, \"count\": 1, \"min\": 18000576, \"max\": 18000576}, \"Total Batches Seen\": {\"sum\": 18033.0, \"count\": 1, \"min\": 18033, \"max\": 18033}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 57.0, \"count\": 1, \"min\": 57, \"max\": 57}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:22 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66427.80319349177 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=11.709746207753607\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=56, batch=0 train mse <loss>=137.11815625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:22 INFO 140714915637056] #quality_metric: host=algo-1, epoch=56, batch=0 train absolute_loss <loss>=4.4029775390625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:27.150] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 4793, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=15.18437448019794\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=56, train mse <loss>=230.56522835488644\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=56, train absolute_loss <loss>=4.515324912124539\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561082.3531606, \"EndTime\": 1635561087.151374, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4795.918703079224, \"count\": 1, \"min\": 4795.918703079224, \"max\": 4795.918703079224}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:27 INFO 140714915637056] #progress_metric: host=algo-1, completed 64.77272727272727 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561082.3554199, \"EndTime\": 1635561087.151797, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 56, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18321997.0, \"count\": 1, \"min\": 18321997, \"max\": 18321997}, \"Total Batches Seen\": {\"sum\": 18355.0, \"count\": 1, \"min\": 18355, \"max\": 18355}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 58.0, \"count\": 1, \"min\": 58, \"max\": 58}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:27 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=67010.68204375272 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=11.186529287495743\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=57, batch=0 train mse <loss>=125.1384375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:27 INFO 140714915637056] #quality_metric: host=algo-1, epoch=57, batch=0 train absolute_loss <loss>=4.086126953125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:31:32.019] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 4863, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=15.425885734757358\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=57, train mse <loss>=237.95795070179057\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=57, train absolute_loss <loss>=4.672830558824243\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561087.151506, \"EndTime\": 1635561092.0204298, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4866.399765014648, \"count\": 1, \"min\": 4866.399765014648, \"max\": 4866.399765014648}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:32 INFO 140714915637056] #progress_metric: host=algo-1, completed 65.9090909090909 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561087.1539993, \"EndTime\": 1635561092.0206735, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 57, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18643418.0, \"count\": 1, \"min\": 18643418, \"max\": 18643418}, \"Total Batches Seen\": {\"sum\": 18677.0, \"count\": 1, \"min\": 18677, \"max\": 18677}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 59.0, \"count\": 1, \"min\": 59, \"max\": 59}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:32 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66043.64265800336 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=12.788211123921906\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=58, batch=0 train mse <loss>=163.53834375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:32 INFO 140714915637056] #quality_metric: host=algo-1, epoch=58, batch=0 train absolute_loss <loss>=4.66332275390625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:36.845] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 4820, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=19.033254549071238\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=58, train mse <loss>=362.2647787297409\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=58, train absolute_loss <loss>=5.65140359136925\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561092.020508, \"EndTime\": 1635561096.8456354, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4822.838544845581, \"count\": 1, \"min\": 4822.838544845581, \"max\": 4822.838544845581}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:36 INFO 140714915637056] #progress_metric: host=algo-1, completed 67.04545454545455 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561092.022767, \"EndTime\": 1635561096.845882, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 58, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18964839.0, \"count\": 1, \"min\": 18964839, \"max\": 18964839}, \"Total Batches Seen\": {\"sum\": 18999.0, \"count\": 1, \"min\": 18999, \"max\": 18999}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 60.0, \"count\": 1, \"min\": 60, \"max\": 60}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:36 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66640.16091978569 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=14.538382389385692\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=59, batch=0 train mse <loss>=211.3645625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=59, batch=0 train absolute_loss <loss>=5.71711474609375\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:41.755] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 4907, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=11.184224349273103\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=59, train mse <loss>=125.08687429487335\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=59, train absolute_loss <loss>=2.845786433439077\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561096.845716, \"EndTime\": 1635561101.7568142, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4910.627841949463, \"count\": 1, \"min\": 4910.627841949463, \"max\": 4910.627841949463}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:41 INFO 140714915637056] #progress_metric: host=algo-1, completed 68.18181818181819 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561096.8461518, \"EndTime\": 1635561101.7571244, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 59, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19286260.0, \"count\": 1, \"min\": 19286260, \"max\": 19286260}, \"Total Batches Seen\": {\"sum\": 19321.0, \"count\": 1, \"min\": 19321, \"max\": 19321}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 61.0, \"count\": 1, \"min\": 61, \"max\": 61}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:41 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65447.419376268095 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=7.059955293767801\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=60, batch=0 train mse <loss>=49.84296875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=60, batch=0 train absolute_loss <loss>=1.6439493408203125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:46.796] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 5035, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=9.858944076311676\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=60, train mse <loss>=97.19877829984108\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=60, train absolute_loss <loss>=2.02001535394325\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561101.7569196, \"EndTime\": 1635561106.7973404, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5037.9884243011475, \"count\": 1, \"min\": 5037.9884243011475, \"max\": 5037.9884243011475}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:46 INFO 140714915637056] #progress_metric: host=algo-1, completed 69.31818181818181 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561101.7593164, \"EndTime\": 1635561106.797629, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 60, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19607681.0, \"count\": 1, \"min\": 19607681, \"max\": 19607681}, \"Total Batches Seen\": {\"sum\": 19643.0, \"count\": 1, \"min\": 19643, \"max\": 19643}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 62.0, \"count\": 1, \"min\": 62, \"max\": 62}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:46 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63793.73262928886 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=7.719262634798741\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=61, batch=0 train mse <loss>=59.587015625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=61, batch=0 train absolute_loss <loss>=2.38720947265625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:31:51.651] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 4850, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=10.246410369923279\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=61, train mse <loss>=104.98892546887132\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=61, train absolute_loss <loss>=2.3043053164274796\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561106.797435, \"EndTime\": 1635561111.6522756, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4852.599143981934, \"count\": 1, \"min\": 4852.599143981934, \"max\": 4852.599143981934}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:51 INFO 140714915637056] #progress_metric: host=algo-1, completed 70.45454545454545 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561106.799646, \"EndTime\": 1635561111.6525092, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 61, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19929102.0, \"count\": 1, \"min\": 19929102, \"max\": 19929102}, \"Total Batches Seen\": {\"sum\": 19965.0, \"count\": 1, \"min\": 19965, \"max\": 19965}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 63.0, \"count\": 1, \"min\": 63, \"max\": 63}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:51 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66231.59299311679 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=8.34470032041295\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=62, batch=0 train mse <loss>=69.6340234375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=62, batch=0 train absolute_loss <loss>=2.527724365234375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:31:56.567] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 4910, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=9.047460673948693\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=62, train mse <loss>=81.85654464664815\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=62, train absolute_loss <loss>=1.468219406412255\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561111.6523528, \"EndTime\": 1635561116.568191, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4913.503885269165, \"count\": 1, \"min\": 4913.503885269165, \"max\": 4913.503885269165}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:56 INFO 140714915637056] #progress_metric: host=algo-1, completed 71.5909090909091 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561111.654656, \"EndTime\": 1635561116.5684583, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 62, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20250523.0, \"count\": 1, \"min\": 20250523, \"max\": 20250523}, \"Total Batches Seen\": {\"sum\": 20287.0, \"count\": 1, \"min\": 20287, \"max\": 20287}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 64.0, \"count\": 1, \"min\": 64, \"max\": 64}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:56 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65410.20004913028 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=6.80914854488063\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=63, batch=0 train mse <loss>=46.36450390625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:31:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=63, batch=0 train absolute_loss <loss>=1.41825048828125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:01.374] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 4802, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=9.295438255171149\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=63, train mse <loss>=86.40517235569925\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=63, train absolute_loss <loss>=1.7143172395125679\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561116.5682774, \"EndTime\": 1635561121.3753111, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4804.64506149292, \"count\": 1, \"min\": 4804.64506149292, \"max\": 4804.64506149292}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:01 INFO 140714915637056] #progress_metric: host=algo-1, completed 72.72727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561116.5706332, \"EndTime\": 1635561121.3756368, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 63, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20571944.0, \"count\": 1, \"min\": 20571944, \"max\": 20571944}, \"Total Batches Seen\": {\"sum\": 20609.0, \"count\": 1, \"min\": 20609, \"max\": 20609}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 65.0, \"count\": 1, \"min\": 65, \"max\": 65}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:01 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66890.54121158776 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=7.0659778494381085\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=64, batch=0 train mse <loss>=49.92804296875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=64, batch=0 train absolute_loss <loss>=1.6803787841796876\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:06.876] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 5497, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=9.029541099969636\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=64, train mse <loss>=81.53261247604085\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=64, train absolute_loss <loss>=1.431795385325177\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561121.3754306, \"EndTime\": 1635561126.8788776, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5501.052379608154, \"count\": 1, \"min\": 5501.052379608154, \"max\": 5501.052379608154}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:06 INFO 140714915637056] #progress_metric: host=algo-1, completed 73.86363636363636 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561121.3777893, \"EndTime\": 1635561126.8792942, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 64, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 20893365.0, \"count\": 1, \"min\": 20893365, \"max\": 20893365}, \"Total Batches Seen\": {\"sum\": 20931.0, \"count\": 1, \"min\": 20931, \"max\": 20931}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:06 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=58421.85144525178 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=7.124427060297551\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=65, batch=0 train mse <loss>=50.7574609375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=65, batch=0 train absolute_loss <loss>=1.7393912353515626\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:12.001] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 5116, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=9.01055834137754\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=65, train mse <loss>=81.19016162336835\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=65, train absolute_loss <loss>=1.4634392161872816\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561126.8790352, \"EndTime\": 1635561132.0024228, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5120.39852142334, \"count\": 1, \"min\": 5120.39852142334, \"max\": 5120.39852142334}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:12 INFO 140714915637056] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561126.8819911, \"EndTime\": 1635561132.0027025, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 65, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21214786.0, \"count\": 1, \"min\": 21214786, \"max\": 21214786}, \"Total Batches Seen\": {\"sum\": 21253.0, \"count\": 1, \"min\": 21253, \"max\": 21253}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 67.0, \"count\": 1, \"min\": 67, \"max\": 67}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:12 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=62767.027091035925 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=6.676368949043335\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=66, batch=0 train mse <loss>=44.57390234375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:12 INFO 140714915637056] #quality_metric: host=algo-1, epoch=66, batch=0 train absolute_loss <loss>=1.2615372314453126\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:17.052] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 5045, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=8.888756385482743\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=66, train mse <loss>=79.00999008046026\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=66, train absolute_loss <loss>=1.2838831106624249\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561132.0025156, \"EndTime\": 1635561137.0534947, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5048.691272735596, \"count\": 1, \"min\": 5048.691272735596, \"max\": 5048.691272735596}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:17 INFO 140714915637056] #progress_metric: host=algo-1, completed 76.13636363636364 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561132.0047686, \"EndTime\": 1635561137.0538323, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 66, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21536207.0, \"count\": 1, \"min\": 21536207, \"max\": 21536207}, \"Total Batches Seen\": {\"sum\": 21575.0, \"count\": 1, \"min\": 21575, \"max\": 21575}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 68.0, \"count\": 1, \"min\": 68, \"max\": 68}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:17 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63657.53591982612 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=6.896240483952107\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=67, batch=0 train mse <loss>=47.5581328125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:17 INFO 140714915637056] #quality_metric: host=algo-1, epoch=67, batch=0 train absolute_loss <loss>=1.5133499755859374\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:32:21.944] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 4886, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=8.797594254153822\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=67, train mse <loss>=77.39766466072035\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=67, train absolute_loss <loss>=1.1828566549549933\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561137.0535917, \"EndTime\": 1635561141.9458494, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4889.866352081299, \"count\": 1, \"min\": 4889.866352081299, \"max\": 4889.866352081299}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:21 INFO 140714915637056] #progress_metric: host=algo-1, completed 77.27272727272727 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561137.0559494, \"EndTime\": 1635561141.9461377, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 67, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 21857628.0, \"count\": 1, \"min\": 21857628, \"max\": 21857628}, \"Total Batches Seen\": {\"sum\": 21897.0, \"count\": 1, \"min\": 21897, \"max\": 21897}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 69.0, \"count\": 1, \"min\": 69, \"max\": 69}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:21 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65725.56658435395 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=6.70835474893062\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=68, batch=0 train mse <loss>=45.0020234375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=68, batch=0 train absolute_loss <loss>=1.28050048828125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:26.732] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 4782, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=8.742748913451045\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=68, train mse <loss>=76.43565856364943\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=68, train absolute_loss <loss>=1.0990389533190994\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561141.9459481, \"EndTime\": 1635561146.7337408, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4785.545587539673, \"count\": 1, \"min\": 4785.545587539673, \"max\": 4785.545587539673}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:26 INFO 140714915637056] #progress_metric: host=algo-1, completed 78.4090909090909 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561141.9481635, \"EndTime\": 1635561146.7339811, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 68, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22179049.0, \"count\": 1, \"min\": 22179049, \"max\": 22179049}, \"Total Batches Seen\": {\"sum\": 22219.0, \"count\": 1, \"min\": 22219, \"max\": 22219}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 70.0, \"count\": 1, \"min\": 70, \"max\": 70}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:26 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=67159.4304516156 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=6.6148468779519\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=69, batch=0 train mse <loss>=43.75619921875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=69, batch=0 train absolute_loss <loss>=1.1543333740234376\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:31.677] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 4939, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=8.736618102327164\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=69, train mse <loss>=76.3284958659107\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=69, train absolute_loss <loss>=1.0853369316906663\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561146.7338235, \"EndTime\": 1635561151.678432, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4942.312479019165, \"count\": 1, \"min\": 4942.312479019165, \"max\": 4942.312479019165}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:31 INFO 140714915637056] #progress_metric: host=algo-1, completed 79.54545454545455 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561146.736089, \"EndTime\": 1635561151.6786602, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 69, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22500470.0, \"count\": 1, \"min\": 22500470, \"max\": 22500470}, \"Total Batches Seen\": {\"sum\": 22541.0, \"count\": 1, \"min\": 22541, \"max\": 22541}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:31 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65029.57656572899 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=6.600674977322395\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=70, batch=0 train mse <loss>=43.56891015625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=70, batch=0 train absolute_loss <loss>=1.1652548828125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:36.577] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 4895, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=8.78878158615516\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=70, train mse <loss>=77.24268176914002\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=70, train absolute_loss <loss>=1.1309909929547992\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561151.6785083, \"EndTime\": 1635561156.5787222, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4897.988319396973, \"count\": 1, \"min\": 4897.988319396973, \"max\": 4897.988319396973}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:36 INFO 140714915637056] #progress_metric: host=algo-1, completed 80.68181818181819 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561151.6807, \"EndTime\": 1635561156.5790024, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 70, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22821891.0, \"count\": 1, \"min\": 22821891, \"max\": 22821891}, \"Total Batches Seen\": {\"sum\": 22863.0, \"count\": 1, \"min\": 22863, \"max\": 22863}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:36 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65616.89614668029 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=6.600180217709967\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=71, batch=0 train mse <loss>=43.56237890625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=71, batch=0 train absolute_loss <loss>=1.141300048828125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:41.354] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 4773, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=8.90588335743413\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=71, train mse <loss>=79.31475837622222\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=71, train absolute_loss <loss>=1.2010724159382886\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561156.5788066, \"EndTime\": 1635561161.3554978, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4776.09395980835, \"count\": 1, \"min\": 4776.09395980835, \"max\": 4776.09395980835}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:41 INFO 140714915637056] #progress_metric: host=algo-1, completed 81.81818181818181 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561156.579365, \"EndTime\": 1635561161.3557975, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 71, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23143312.0, \"count\": 1, \"min\": 23143312, \"max\": 23143312}, \"Total Batches Seen\": {\"sum\": 23185.0, \"count\": 1, \"min\": 23185, \"max\": 23185}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:41 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=67290.89008559298 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=6.605428342942644\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=72, batch=0 train mse <loss>=43.63168359375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:41 INFO 140714915637056] #quality_metric: host=algo-1, epoch=72, batch=0 train absolute_loss <loss>=1.22855029296875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:32:46.337] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 4977, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=9.219008800151766\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=72, train mse <loss>=84.9901232572757\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=72, train absolute_loss <loss>=1.3323067096212635\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561161.3555932, \"EndTime\": 1635561166.338951, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4980.929613113403, \"count\": 1, \"min\": 4980.929613113403, \"max\": 4980.929613113403}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:46 INFO 140714915637056] #progress_metric: host=algo-1, completed 82.95454545454545 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561161.3579628, \"EndTime\": 1635561166.3392878, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 72, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23464733.0, \"count\": 1, \"min\": 23464733, \"max\": 23464733}, \"Total Batches Seen\": {\"sum\": 23507.0, \"count\": 1, \"min\": 23507, \"max\": 23507}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 74.0, \"count\": 1, \"min\": 74, \"max\": 74}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:46 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=64523.26027428206 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=6.629055067937662\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=73, batch=0 train mse <loss>=43.94437109375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:46 INFO 140714915637056] #quality_metric: host=algo-1, epoch=73, batch=0 train absolute_loss <loss>=1.199059326171875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:51.224] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 4879, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=9.10631378249193\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=73, train mse <loss>=82.92495070520248\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=73, train absolute_loss <loss>=1.3111228664232337\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561166.3390508, \"EndTime\": 1635561171.2252097, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4882.766246795654, \"count\": 1, \"min\": 4882.766246795654, \"max\": 4882.766246795654}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:51 INFO 140714915637056] #progress_metric: host=algo-1, completed 84.0909090909091 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561166.3424041, \"EndTime\": 1635561171.2255168, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 73, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23786154.0, \"count\": 1, \"min\": 23786154, \"max\": 23786154}, \"Total Batches Seen\": {\"sum\": 23829.0, \"count\": 1, \"min\": 23829, \"max\": 23829}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:51 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65820.70226969423 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=6.633854636917364\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=74, batch=0 train mse <loss>=44.00802734375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:51 INFO 140714915637056] #quality_metric: host=algo-1, epoch=74, batch=0 train absolute_loss <loss>=1.2038214111328125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:32:56.087] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 4858, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=8.856332442967878\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=74, train mse <loss>=78.43462434036539\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=74, train absolute_loss <loss>=1.1797888983495488\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561171.2253227, \"EndTime\": 1635561176.0887303, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4861.222982406616, \"count\": 1, \"min\": 4861.222982406616, \"max\": 4861.222982406616}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:56 INFO 140714915637056] #progress_metric: host=algo-1, completed 85.22727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561171.227477, \"EndTime\": 1635561176.0889637, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 74, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24107575.0, \"count\": 1, \"min\": 24107575, \"max\": 24107575}, \"Total Batches Seen\": {\"sum\": 24151.0, \"count\": 1, \"min\": 24151, \"max\": 24151}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:56 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66114.15574054408 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=6.595562250957078\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=75, batch=0 train mse <loss>=43.50144140625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:32:56 INFO 140714915637056] #quality_metric: host=algo-1, epoch=75, batch=0 train absolute_loss <loss>=1.1359461669921875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:01.001] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 4908, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=8.709332937176224\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=75, train mse <loss>=75.85248021058266\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=75, train absolute_loss <loss>=1.046304536618061\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561176.0888076, \"EndTime\": 1635561181.0021746, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4911.144256591797, \"count\": 1, \"min\": 4911.144256591797, \"max\": 4911.144256591797}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:01 INFO 140714915637056] #progress_metric: host=algo-1, completed 86.36363636363636 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561176.0910053, \"EndTime\": 1635561181.002349, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 75, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24428996.0, \"count\": 1, \"min\": 24428996, \"max\": 24428996}, \"Total Batches Seen\": {\"sum\": 24473.0, \"count\": 1, \"min\": 24473, \"max\": 24473}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 77.0, \"count\": 1, \"min\": 77, \"max\": 77}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:01 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65443.120844184596 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=6.58087308987189\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=76, batch=0 train mse <loss>=43.307890625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:01 INFO 140714915637056] #quality_metric: host=algo-1, epoch=76, batch=0 train absolute_loss <loss>=1.161720703125\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:06.725] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 5719, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=8.773501663502113\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=76, train mse <loss>=76.97433143947435\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=76, train absolute_loss <loss>=1.1033900495256697\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561181.0022335, \"EndTime\": 1635561186.7262435, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5721.881628036499, \"count\": 1, \"min\": 5721.881628036499, \"max\": 5721.881628036499}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:06 INFO 140714915637056] #progress_metric: host=algo-1, completed 87.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561181.0043116, \"EndTime\": 1635561186.7264707, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 76, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 24750417.0, \"count\": 1, \"min\": 24750417, \"max\": 24750417}, \"Total Batches Seen\": {\"sum\": 24795.0, \"count\": 1, \"min\": 24795, \"max\": 24795}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 78.0, \"count\": 1, \"min\": 78, \"max\": 78}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:06 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=56170.00385750272 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=6.579207007212191\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=77, batch=0 train mse <loss>=43.28596484375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:06 INFO 140714915637056] #quality_metric: host=algo-1, epoch=77, batch=0 train absolute_loss <loss>=1.1154569091796875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:33:11.641] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 4910, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:11 INFO 140714915637056] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=8.841362580040256\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:11 INFO 140714915637056] #quality_metric: host=algo-1, epoch=77, train mse <loss>=78.1696922717361\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:11 INFO 140714915637056] #quality_metric: host=algo-1, epoch=77, train absolute_loss <loss>=1.1683158252787145\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561186.72632, \"EndTime\": 1635561191.6418748, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4913.248062133789, \"count\": 1, \"min\": 4913.248062133789, \"max\": 4913.248062133789}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:11 INFO 140714915637056] #progress_metric: host=algo-1, completed 88.63636363636364 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561186.728592, \"EndTime\": 1635561191.6421762, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 77, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25071838.0, \"count\": 1, \"min\": 25071838, \"max\": 25071838}, \"Total Batches Seen\": {\"sum\": 25117.0, \"count\": 1, \"min\": 25117, \"max\": 25117}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 79.0, \"count\": 1, \"min\": 79, \"max\": 79}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:11 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65412.93266191957 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:11 INFO 140714915637056] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=6.6130667880908325\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:11 INFO 140714915637056] #quality_metric: host=algo-1, epoch=78, batch=0 train mse <loss>=43.73265234375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:11 INFO 140714915637056] #quality_metric: host=algo-1, epoch=78, batch=0 train absolute_loss <loss>=1.2629010009765624\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:16.667] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 5021, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:16 INFO 140714915637056] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=9.091006322509578\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:16 INFO 140714915637056] #quality_metric: host=algo-1, epoch=78, train mse <loss>=82.64639595590911\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:16 INFO 140714915637056] #quality_metric: host=algo-1, epoch=78, train absolute_loss <loss>=1.2105985133958899\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561191.6419744, \"EndTime\": 1635561196.6685975, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5024.340629577637, \"count\": 1, \"min\": 5024.340629577637, \"max\": 5024.340629577637}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:16 INFO 140714915637056] #progress_metric: host=algo-1, completed 89.77272727272727 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561191.6442235, \"EndTime\": 1635561196.6688952, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 78, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25393259.0, \"count\": 1, \"min\": 25393259, \"max\": 25393259}, \"Total Batches Seen\": {\"sum\": 25439.0, \"count\": 1, \"min\": 25439, \"max\": 25439}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 80.0, \"count\": 1, \"min\": 80, \"max\": 80}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:16 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63966.656175116404 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:16 INFO 140714915637056] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=6.599243860568421\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:16 INFO 140714915637056] #quality_metric: host=algo-1, epoch=79, batch=0 train mse <loss>=43.55001953125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:16 INFO 140714915637056] #quality_metric: host=algo-1, epoch=79, batch=0 train absolute_loss <loss>=1.1376773681640624\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:21.570] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 4898, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=9.07717894887657\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=79, train mse <loss>=82.39517766992795\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=79, train absolute_loss <loss>=1.2625999909395016\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561196.6686938, \"EndTime\": 1635561201.5715594, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4900.5446434021, \"count\": 1, \"min\": 4900.5446434021, \"max\": 4900.5446434021}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:21 INFO 140714915637056] #progress_metric: host=algo-1, completed 90.9090909090909 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561196.670984, \"EndTime\": 1635561201.5717967, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 79, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25714680.0, \"count\": 1, \"min\": 25714680, \"max\": 25714680}, \"Total Batches Seen\": {\"sum\": 25761.0, \"count\": 1, \"min\": 25761, \"max\": 25761}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:21 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65583.57380547657 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=6.610952973569695\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=80, batch=0 train mse <loss>=43.70469921875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:21 INFO 140714915637056] #quality_metric: host=algo-1, epoch=80, batch=0 train absolute_loss <loss>=1.223047607421875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:26.392] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 4819, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=8.914288683190772\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=80, train mse <loss>=79.46454272726308\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=80, train absolute_loss <loss>=1.206545105359569\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561201.5716395, \"EndTime\": 1635561206.3936214, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4821.536064147949, \"count\": 1, \"min\": 4821.536064147949, \"max\": 4821.536064147949}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:26 INFO 140714915637056] #progress_metric: host=algo-1, completed 92.04545454545455 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561201.572051, \"EndTime\": 1635561206.3938663, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 80, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26036101.0, \"count\": 1, \"min\": 26036101, \"max\": 26036101}, \"Total Batches Seen\": {\"sum\": 26083.0, \"count\": 1, \"min\": 26083, \"max\": 26083}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:26 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66658.10546630752 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=6.594251758160284\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=81, batch=0 train mse <loss>=43.48415625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:26 INFO 140714915637056] #quality_metric: host=algo-1, epoch=81, batch=0 train absolute_loss <loss>=1.1544654541015624\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:33:31.218] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 4820, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=8.736777408542876\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=81, train mse <loss>=76.33127948642517\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=81, train absolute_loss <loss>=1.0825448195179057\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561206.3936946, \"EndTime\": 1635561211.2189252, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4822.966575622559, \"count\": 1, \"min\": 4822.966575622559, \"max\": 4822.966575622559}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:31 INFO 140714915637056] #progress_metric: host=algo-1, completed 93.18181818181819 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561206.395926, \"EndTime\": 1635561211.2192087, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 81, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26357522.0, \"count\": 1, \"min\": 26357522, \"max\": 26357522}, \"Total Batches Seen\": {\"sum\": 26405.0, \"count\": 1, \"min\": 26405, \"max\": 26405}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 83.0, \"count\": 1, \"min\": 83, \"max\": 83}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:31 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66637.62455265156 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=6.576324426969065\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=82, batch=0 train mse <loss>=43.24804296875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:31 INFO 140714915637056] #quality_metric: host=algo-1, epoch=82, batch=0 train absolute_loss <loss>=1.1891610107421875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:36.070] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 4847, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=8.861050258730033\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=82, train mse <loss>=78.5182116877396\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=82, train absolute_loss <loss>=1.1465058097128542\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561211.219015, \"EndTime\": 1635561216.0712607, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4849.978685379028, \"count\": 1, \"min\": 4849.978685379028, \"max\": 4849.978685379028}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:36 INFO 140714915637056] #progress_metric: host=algo-1, completed 94.31818181818181 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561211.2212515, \"EndTime\": 1635561216.0715234, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 82, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26678943.0, \"count\": 1, \"min\": 26678943, \"max\": 26678943}, \"Total Batches Seen\": {\"sum\": 26727.0, \"count\": 1, \"min\": 26727, \"max\": 26727}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 84.0, \"count\": 1, \"min\": 84, \"max\": 84}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:36 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66267.03651098908 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=83, batch=0 train rmse <loss>=6.5741028380304485\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=83, batch=0 train mse <loss>=43.218828125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:36 INFO 140714915637056] #quality_metric: host=algo-1, epoch=83, batch=0 train absolute_loss <loss>=1.116904296875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:40.957] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 168, \"duration\": 4881, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:40 INFO 140714915637056] #quality_metric: host=algo-1, epoch=83, train rmse <loss>=8.971339259303164\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:40 INFO 140714915637056] #quality_metric: host=algo-1, epoch=83, train mse <loss>=80.48492810551424\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:40 INFO 140714915637056] #quality_metric: host=algo-1, epoch=83, train absolute_loss <loss>=1.1962160915588\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561216.0713592, \"EndTime\": 1635561220.9581974, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4884.052276611328, \"count\": 1, \"min\": 4884.052276611328, \"max\": 4884.052276611328}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:40 INFO 140714915637056] #progress_metric: host=algo-1, completed 95.45454545454545 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561216.074114, \"EndTime\": 1635561220.9584446, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 83, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27000364.0, \"count\": 1, \"min\": 27000364, \"max\": 27000364}, \"Total Batches Seen\": {\"sum\": 27049.0, \"count\": 1, \"min\": 27049, \"max\": 27049}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 85.0, \"count\": 1, \"min\": 85, \"max\": 85}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:40 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=65804.93694591653 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:40 INFO 140714915637056] #quality_metric: host=algo-1, epoch=84, batch=0 train rmse <loss>=6.591418722949559\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:40 INFO 140714915637056] #quality_metric: host=algo-1, epoch=84, batch=0 train mse <loss>=43.44680078125\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:40 INFO 140714915637056] #quality_metric: host=algo-1, epoch=84, batch=0 train absolute_loss <loss>=1.215584716796875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:45.812] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 170, \"duration\": 4850, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:45 INFO 140714915637056] #quality_metric: host=algo-1, epoch=84, train rmse <loss>=9.225991689401955\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:45 INFO 140714915637056] #quality_metric: host=algo-1, epoch=84, train mse <loss>=85.11892265291392\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:45 INFO 140714915637056] #quality_metric: host=algo-1, epoch=84, train absolute_loss <loss>=1.3445409663419545\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561220.9582849, \"EndTime\": 1635561225.813572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4852.947473526001, \"count\": 1, \"min\": 4852.947473526001, \"max\": 4852.947473526001}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:45 INFO 140714915637056] #progress_metric: host=algo-1, completed 96.5909090909091 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561220.960596, \"EndTime\": 1635561225.8138201, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 84, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27321785.0, \"count\": 1, \"min\": 27321785, \"max\": 27321785}, \"Total Batches Seen\": {\"sum\": 27371.0, \"count\": 1, \"min\": 27371, \"max\": 27371}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 86.0, \"count\": 1, \"min\": 86, \"max\": 86}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:45 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66226.58571131158 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:45 INFO 140714915637056] #quality_metric: host=algo-1, epoch=85, batch=0 train rmse <loss>=6.650246118565839\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:45 INFO 140714915637056] #quality_metric: host=algo-1, epoch=85, batch=0 train mse <loss>=44.2257734375\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:45 INFO 140714915637056] #quality_metric: host=algo-1, epoch=85, batch=0 train absolute_loss <loss>=1.266813232421875\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:33:50.892] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 172, \"duration\": 5075, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:50 INFO 140714915637056] #quality_metric: host=algo-1, epoch=85, train rmse <loss>=8.949251727326281\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:50 INFO 140714915637056] #quality_metric: host=algo-1, epoch=85, train mse <loss>=80.08910647905243\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:50 INFO 140714915637056] #quality_metric: host=algo-1, epoch=85, train absolute_loss <loss>=1.251807430480578\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561225.8136518, \"EndTime\": 1635561230.8932366, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5077.383756637573, \"count\": 1, \"min\": 5077.383756637573, \"max\": 5077.383756637573}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:50 INFO 140714915637056] #progress_metric: host=algo-1, completed 97.72727272727273 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561225.8158216, \"EndTime\": 1635561230.8935204, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 85, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27643206.0, \"count\": 1, \"min\": 27643206, \"max\": 27643206}, \"Total Batches Seen\": {\"sum\": 27693.0, \"count\": 1, \"min\": 27693, \"max\": 27693}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 87.0, \"count\": 1, \"min\": 87, \"max\": 87}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:50 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=63298.93311712471 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:50 INFO 140714915637056] #quality_metric: host=algo-1, epoch=86, batch=0 train rmse <loss>=6.5777421206862465\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:50 INFO 140714915637056] #quality_metric: host=algo-1, epoch=86, batch=0 train mse <loss>=43.26669140625\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:50 INFO 140714915637056] #quality_metric: host=algo-1, epoch=86, batch=0 train absolute_loss <loss>=1.1519229736328125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-10-30 02:33:55.679] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 174, \"duration\": 4782, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:55 INFO 140714915637056] #quality_metric: host=algo-1, epoch=86, train rmse <loss>=8.883343536186285\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:55 INFO 140714915637056] #quality_metric: host=algo-1, epoch=86, train mse <loss>=78.91379238190265\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:55 INFO 140714915637056] #quality_metric: host=algo-1, epoch=86, train absolute_loss <loss>=1.2241861991171512\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561230.8933496, \"EndTime\": 1635561235.680538, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4784.824848175049, \"count\": 1, \"min\": 4784.824848175049, \"max\": 4784.824848175049}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:55 INFO 140714915637056] #progress_metric: host=algo-1, completed 98.86363636363636 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561230.8956828, \"EndTime\": 1635561235.6807795, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 86, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27964627.0, \"count\": 1, \"min\": 27964627, \"max\": 27964627}, \"Total Batches Seen\": {\"sum\": 28015.0, \"count\": 1, \"min\": 28015, \"max\": 28015}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 88.0, \"count\": 1, \"min\": 88, \"max\": 88}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:55 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=67169.60609957448 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:55 INFO 140714915637056] #quality_metric: host=algo-1, epoch=87, batch=0 train rmse <loss>=6.590721164542618\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:55 INFO 140714915637056] #quality_metric: host=algo-1, epoch=87, batch=0 train mse <loss>=43.43760546875\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:33:55 INFO 140714915637056] #quality_metric: host=algo-1, epoch=87, batch=0 train absolute_loss <loss>=1.171818603515625\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:34:00.526] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 176, \"duration\": 4841, \"num_examples\": 322, \"num_bytes\": 33805260}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] #quality_metric: host=algo-1, epoch=87, train rmse <loss>=8.703088234402932\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] #quality_metric: host=algo-1, epoch=87, train mse <loss>=75.74374481580273\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] #quality_metric: host=algo-1, epoch=87, train absolute_loss <loss>=1.0812077574167192\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] #quality_metric: host=algo-1, train rmse <loss>=8.703088234402932\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] #quality_metric: host=algo-1, train mse <loss>=75.74374481580273\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] #quality_metric: host=algo-1, train absolute_loss <loss>=1.0812077574167192\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561235.6806247, \"EndTime\": 1635561240.527546, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4844.632625579834, \"count\": 1, \"min\": 4844.632625579834, \"max\": 4844.632625579834}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561235.6828785, \"EndTime\": 1635561240.5278246, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 87, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28286048.0, \"count\": 1, \"min\": 28286048, \"max\": 28286048}, \"Total Batches Seen\": {\"sum\": 28337.0, \"count\": 1, \"min\": 28337, \"max\": 28337}, \"Max Records Seen Between Resets\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Max Batches Seen Between Resets\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}, \"Reset Count\": {\"sum\": 89.0, \"count\": 1, \"min\": 89, \"max\": 89}, \"Number of Records Since Last Reset\": {\"sum\": 321421.0, \"count\": 1, \"min\": 321421, \"max\": 321421}, \"Number of Batches Since Last Reset\": {\"sum\": 322.0, \"count\": 1, \"min\": 322, \"max\": 322}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] #throughput_metric: host=algo-1, train throughput=66339.45421302164 records/second\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 WARNING 140714915637056] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561240.5276375, \"EndTime\": 1635561240.5678725, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 39.61491584777832, \"count\": 1, \"min\": 39.61491584777832, \"max\": 39.61491584777832}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:00 INFO 140714915637056] Saved checkpoint to \"/tmp/tmpep6k2sed/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:34:00.933] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 439487, \"num_examples\": 1, \"num_bytes\": 105436}\u001b[0m\n",
      "\u001b[34m[2021-10-30 02:34:04.854] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 3920, \"num_examples\": 81, \"num_bytes\": 8450640}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561240.9328046, \"EndTime\": 1635561244.8545144, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 80356.0, \"count\": 1, \"min\": 80356, \"max\": 80356}, \"Total Batches Seen\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Max Records Seen Between Resets\": {\"sum\": 80356.0, \"count\": 1, \"min\": 80356, \"max\": 80356}, \"Max Batches Seen Between Resets\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 80356.0, \"count\": 1, \"min\": 80356, \"max\": 80356}, \"Number of Batches Since Last Reset\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}}}\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:04 INFO 140714915637056] #test_score (algo-1) : ('rmse', 5.998567343704953)\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:04 INFO 140714915637056] #test_score (algo-1) : ('mse', 35.98281017696349)\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:04 INFO 140714915637056] #test_score (algo-1) : ('absolute_loss', 1.5712551857703678)\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:04 INFO 140714915637056] #quality_metric: host=algo-1, test rmse <loss>=5.998567343704953\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:04 INFO 140714915637056] #quality_metric: host=algo-1, test mse <loss>=35.98281017696349\u001b[0m\n",
      "\u001b[34m[10/30/2021 02:34:04 INFO 140714915637056] #quality_metric: host=algo-1, test absolute_loss <loss>=1.5712551857703678\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635561240.5680058, \"EndTime\": 1635561244.856408, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 22.129058837890625, \"count\": 1, \"min\": 22.129058837890625, \"max\": 22.129058837890625}, \"totaltime\": {\"sum\": 443444.3175792694, \"count\": 1, \"min\": 443444.3175792694, \"max\": 443444.3175792694}}}\u001b[0m\n",
      "\n",
      "2021-10-30 02:34:21 Uploading - Uploading generated training model\n",
      "2021-10-30 02:34:21 Completed - Training job completed\n",
      "Training seconds: 523\n",
      "Billable seconds: 523\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':train_file_location, \n",
    "               'test':test_file_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training_job_info = sagemaker_boto_client.describe_training_job(TrainingJobName=job_name)\n",
    "# boto3_client = boto3.client(\"sagemaker\")\n",
    "# training_job_info = boto3_client.describe_training_job(TrainingJobName=job_name)\n",
    "# training_job_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.157439Z",
     "iopub.status.idle": "2021-10-26T06:56:30.157936Z",
     "shell.execute_reply": "2021-10-26T06:56:30.157692Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.157644Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "import json\n",
    "\n",
    "class fm_json_serializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "        js = {\"instances\": []}\n",
    "        for row in data:\n",
    "            js[\"instances\"].append({\"features\": row.tolist()})\n",
    "        return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.161277Z",
     "iopub.status.idle": "2021-10-26T06:56:30.161741Z",
     "shell.execute_reply": "2021-10-26T06:56:30.161507Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.161483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count = 1,\n",
    "                             instance_type = \"ml.m5.xlarge\",\n",
    "                             endpoint_name = job_name,\n",
    "                             serializer = fm_json_serializer(),\n",
    "                             deserializer = JSONDeserializer(),\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Spender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:06:38.154714Z",
     "iopub.status.busy": "2021-10-26T07:06:38.154337Z",
     "iopub.status.idle": "2021-10-26T07:06:38.840017Z",
     "shell.execute_reply": "2021-10-26T07:06:38.838388Z",
     "shell.execute_reply.started": "2021-10-26T07:06:38.154679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer ID of top spender: 5032.0\n"
     ]
    }
   ],
   "source": [
    "# Find customer who spent the most money\n",
    "\n",
    "df = pd.read_csv(\"fm_preprocessed.zip\")\n",
    "df[\"category_name_1\"].fillna(\"\", inplace=True)\n",
    "df[\"invoice_amount\"] = df[\"qty_ordered\"] * df[\"price\"]\n",
    "\n",
    "top_spender = (df.groupby(\"Customer ID\").sum()[\"invoice_amount\"].sort_values(ascending=False).index[0])\n",
    "print(\"Customer ID of top spender:\", top_spender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:11:41.055450Z",
     "iopub.status.busy": "2021-10-26T07:11:41.054418Z",
     "iopub.status.idle": "2021-10-26T07:11:41.103574Z",
     "shell.execute_reply": "2021-10-26T07:11:41.102476Z",
     "shell.execute_reply.started": "2021-10-26T07:11:41.055357Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>category_name_1</th>\n",
       "      <th>sku_and_cat</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>price</th>\n",
       "      <th>qty_ordered</th>\n",
       "      <th>invoice_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>AKL_A131135338-FW-18-Orange</td>\n",
       "      <td>Women's Fashion</td>\n",
       "      <td>AKL A131135338 FW 18 Orange Women's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>AKL_A131138782-SS-117-17</td>\n",
       "      <td>Women's Fashion</td>\n",
       "      <td>AKL A131138782 SS 117 17 Women's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>AKL_A131138785-SS-119-17</td>\n",
       "      <td>Women's Fashion</td>\n",
       "      <td>AKL A131138785 SS 119 17 Women's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>AKL_A131138786-SS-119-17</td>\n",
       "      <td>Women's Fashion</td>\n",
       "      <td>AKL A131138786 SS 119 17 Women's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>AKL_A131138806-SS-130-17</td>\n",
       "      <td>Women's Fashion</td>\n",
       "      <td>AKL A131138806 SS 130 17 Women's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>AKL_A131138807-SS-131-17</td>\n",
       "      <td>Women's Fashion</td>\n",
       "      <td>AKL A131138807 SS 131 17 Women's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>APPDAW59FEF7B84F84B</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>APPDAW59FEF7B84F84B Appliances</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>9894.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37338</th>\n",
       "      <td>Anchor_439-L</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>Anchor 439 L Men's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37536</th>\n",
       "      <td>Anchor_60-L</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>Anchor 60 L Men's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81826</th>\n",
       "      <td>Delsey_207382001</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>Delsey 207382001 Home &amp; Living</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>10656.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81853</th>\n",
       "      <td>Delsey_8903338061328</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>Delsey 8903338061328 Home &amp; Living</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2975.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96301</th>\n",
       "      <td>Fashion Cafe kids_Barcode 12738 - 12-18 mnths</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>Fashion Cafe kids Barcode 12738   12 18 mnths ...</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96312</th>\n",
       "      <td>Fashion Cafe kids_Barcode 12745 - 12-18 mnths</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>Fashion Cafe kids Barcode 12745   12 18 mnths ...</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97480</th>\n",
       "      <td>GA_C-433-136144</td>\n",
       "      <td>Women's Fashion</td>\n",
       "      <td>GA C 433 136144 Women's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103755</th>\n",
       "      <td>GS_BS645-9-12 M</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>GS BS645 9 12 M Kids &amp; Baby</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103759</th>\n",
       "      <td>GS_BS691-9-12 M</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>GS BS691 9 12 M Kids &amp; Baby</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126151</th>\n",
       "      <td>IDROID_BALRX7-Gold</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>IDROID BALRX7 Gold Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>8944.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>17888000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126561</th>\n",
       "      <td>IDROID_BALRX7-Jet black</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>IDROID BALRX7 Jet black Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>8944.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>17888000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131482</th>\n",
       "      <td>Infinix Note 3-2GB-Nationwide-Gold</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>Infinix Note 3 2GB Nationwide Gold Mobiles &amp; T...</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>18599.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131596</th>\n",
       "      <td>Infinix Note 3-2GB-Nationwide-Grey</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>Infinix Note 3 2GB Nationwide Grey Mobiles &amp; T...</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>18599.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167928</th>\n",
       "      <td>MATINF59C9002EA6AF0</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>MATINF59C9002EA6AF0 Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>12789.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171060</th>\n",
       "      <td>MATLEN5A000D63006BF</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>MATLEN5A000D63006BF Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>9799.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172150</th>\n",
       "      <td>MATMOT59FC5E21CF296</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>MATMOT59FC5E21CF296 Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>13916.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173669</th>\n",
       "      <td>MATOPP59D1F6DC12873</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>MATOPP59D1F6DC12873 Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197812</th>\n",
       "      <td>MEFBNB59FC74FDBC09F-L</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>MEFBNB59FC74FDBC09F L Men's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198098</th>\n",
       "      <td>MEFBNB59FC74FFCBC1B-L</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>MEFBNB59FC74FFCBC1B L Men's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198303</th>\n",
       "      <td>MEFBNB59FC74FFCBC1B-M</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>MEFBNB59FC74FFCBC1B M Men's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198868</th>\n",
       "      <td>MEFBNB59FC7507001A7-L</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>MEFBNB59FC7507001A7 L Men's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215698</th>\n",
       "      <td>MEFPAK5A094C054968C-L</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>MEFPAK5A094C054968C L Men's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216439</th>\n",
       "      <td>MEFPAK5A094C0B66DD1-XL</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>MEFPAK5A094C0B66DD1 XL Men's Fashion</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231219</th>\n",
       "      <td>NDF_Channa Roasted 500gm</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>NDF Channa Roasted 500gm Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234220</th>\n",
       "      <td>Nimcos_Black-Pepper-Potato-Sticks-180gm</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>Nimcos Black Pepper Potato Sticks 180gm Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234349</th>\n",
       "      <td>Nimcos_Chilli-Ringz-100gm</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>Nimcos Chilli Ringz 100gm Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234705</th>\n",
       "      <td>Nimcos_Fried-Onion-175gm</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>Nimcos Fried Onion 175gm Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235039</th>\n",
       "      <td>Nimcos_Namak-Paray-200gm</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>Nimcos Namak Paray 200gm Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235243</th>\n",
       "      <td>Nimcos_Potato-Crisps-Spicy-150gm</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>Nimcos Potato Crisps Spicy 150gm Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235278</th>\n",
       "      <td>Nimcos_Potato-Sticks-150gm</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>Nimcos Potato Sticks 150gm Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235312</th>\n",
       "      <td>Nimcos_Potato-Sticks-350gm</td>\n",
       "      <td>Superstore</td>\n",
       "      <td>Nimcos Potato Sticks 350gm Superstore</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235617</th>\n",
       "      <td>Nimcos_Spicy-Potato-Sticks-180gm</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>Nimcos Spicy Potato Sticks 180gm Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263521</th>\n",
       "      <td>RS_Coconut Bites</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>RS Coconut Bites Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263522</th>\n",
       "      <td>RS_Coconut Bites</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>RS Coconut Bites Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266495</th>\n",
       "      <td>RS_cake rusk</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>RS cake rusk Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287957</th>\n",
       "      <td>Saylani_Sehri-and-Iftari-For-One-Person-Per-Day</td>\n",
       "      <td>Others</td>\n",
       "      <td>Saylani Sehri and Iftari For One Person Per Da...</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290562</th>\n",
       "      <td>Storline_30679</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>Storline 30679 Kids &amp; Baby</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290563</th>\n",
       "      <td>Storline_30679</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>Storline 30679 Kids &amp; Baby</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294148</th>\n",
       "      <td>Telemall_ASA Yechun-Gloves</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Telemall ASA Yechun Gloves Health &amp; Sports</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327808</th>\n",
       "      <td>Xiaomi_MI-C6-Gold-64</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>Xiaomi MI C6 Gold 64 Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>25900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327839</th>\n",
       "      <td>Xiaomi_MI-C6-Grey</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>Xiaomi MI C6 Grey Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>20900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347106</th>\n",
       "      <td>electro_Bluetooth Shower Speaker-Blue</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>electro Bluetooth Shower Speaker Blue Mobiles ...</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359740</th>\n",
       "      <td>iPhone7Plus-Red-256GB</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>iPhone7Plus Red 256GB Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>111856.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363081</th>\n",
       "      <td>infinix_Zero 4-Grey</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>infinix Zero 4 Grey Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>22999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380977</th>\n",
       "      <td>peekaboo_Batman-Black-2 Yrs</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>peekaboo Batman Black 2 Yrs Kids &amp; Baby</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381035</th>\n",
       "      <td>peekaboo_Sun-Surf-&amp;-Beach-Sando-2-years</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>peekaboo Sun Surf &amp; Beach Sando 2 years Kids &amp;...</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381045</th>\n",
       "      <td>peekaboo_United-States-of-Awesome-Sando-2-years</td>\n",
       "      <td>Kids &amp; Baby</td>\n",
       "      <td>peekaboo United States of Awesome Sando 2 year...</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395659</th>\n",
       "      <td>sstop_samsungfastcharger</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>sstop samsungfastcharger Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397095</th>\n",
       "      <td>test-product-00</td>\n",
       "      <td></td>\n",
       "      <td>test product 00</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401544</th>\n",
       "      <td>yankee_5038500008357</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>yankee 5038500008357 Home &amp; Living</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401545</th>\n",
       "      <td>yankee_5038500008357</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>yankee 5038500008357 Home &amp; Living</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401555</th>\n",
       "      <td>yankee_5038580000269</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>yankee 5038580000269 Home &amp; Living</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401556</th>\n",
       "      <td>yankee_5038580000269</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>yankee 5038580000269 Home &amp; Living</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sku    category_name_1  \\\n",
       "2649                        AKL_A131135338-FW-18-Orange    Women's Fashion   \n",
       "3528                           AKL_A131138782-SS-117-17    Women's Fashion   \n",
       "3541                           AKL_A131138785-SS-119-17    Women's Fashion   \n",
       "3548                           AKL_A131138786-SS-119-17    Women's Fashion   \n",
       "3670                           AKL_A131138806-SS-130-17    Women's Fashion   \n",
       "3676                           AKL_A131138807-SS-131-17    Women's Fashion   \n",
       "8916                                APPDAW59FEF7B84F84B         Appliances   \n",
       "37338                                      Anchor_439-L      Men's Fashion   \n",
       "37536                                       Anchor_60-L      Men's Fashion   \n",
       "81826                                  Delsey_207382001      Home & Living   \n",
       "81853                              Delsey_8903338061328      Home & Living   \n",
       "96301     Fashion Cafe kids_Barcode 12738 - 12-18 mnths        Kids & Baby   \n",
       "96312     Fashion Cafe kids_Barcode 12745 - 12-18 mnths        Kids & Baby   \n",
       "97480                                   GA_C-433-136144    Women's Fashion   \n",
       "103755                                  GS_BS645-9-12 M        Kids & Baby   \n",
       "103759                                  GS_BS691-9-12 M        Kids & Baby   \n",
       "126151                               IDROID_BALRX7-Gold  Mobiles & Tablets   \n",
       "126561                          IDROID_BALRX7-Jet black  Mobiles & Tablets   \n",
       "131482               Infinix Note 3-2GB-Nationwide-Gold  Mobiles & Tablets   \n",
       "131596               Infinix Note 3-2GB-Nationwide-Grey  Mobiles & Tablets   \n",
       "167928                              MATINF59C9002EA6AF0  Mobiles & Tablets   \n",
       "171060                              MATLEN5A000D63006BF  Mobiles & Tablets   \n",
       "172150                              MATMOT59FC5E21CF296  Mobiles & Tablets   \n",
       "173669                              MATOPP59D1F6DC12873  Mobiles & Tablets   \n",
       "197812                            MEFBNB59FC74FDBC09F-L      Men's Fashion   \n",
       "198098                            MEFBNB59FC74FFCBC1B-L      Men's Fashion   \n",
       "198303                            MEFBNB59FC74FFCBC1B-M      Men's Fashion   \n",
       "198868                            MEFBNB59FC7507001A7-L      Men's Fashion   \n",
       "215698                            MEFPAK5A094C054968C-L      Men's Fashion   \n",
       "216439                           MEFPAK5A094C0B66DD1-XL      Men's Fashion   \n",
       "231219                         NDF_Channa Roasted 500gm            Soghaat   \n",
       "234220          Nimcos_Black-Pepper-Potato-Sticks-180gm            Soghaat   \n",
       "234349                        Nimcos_Chilli-Ringz-100gm            Soghaat   \n",
       "234705                         Nimcos_Fried-Onion-175gm            Soghaat   \n",
       "235039                         Nimcos_Namak-Paray-200gm            Soghaat   \n",
       "235243                 Nimcos_Potato-Crisps-Spicy-150gm            Soghaat   \n",
       "235278                       Nimcos_Potato-Sticks-150gm            Soghaat   \n",
       "235312                       Nimcos_Potato-Sticks-350gm         Superstore   \n",
       "235617                 Nimcos_Spicy-Potato-Sticks-180gm            Soghaat   \n",
       "263521                                 RS_Coconut Bites            Soghaat   \n",
       "263522                                 RS_Coconut Bites            Soghaat   \n",
       "266495                                     RS_cake rusk            Soghaat   \n",
       "287957  Saylani_Sehri-and-Iftari-For-One-Person-Per-Day             Others   \n",
       "290562                                   Storline_30679        Kids & Baby   \n",
       "290563                                   Storline_30679        Kids & Baby   \n",
       "294148                       Telemall_ASA Yechun-Gloves    Health & Sports   \n",
       "327808                             Xiaomi_MI-C6-Gold-64  Mobiles & Tablets   \n",
       "327839                                Xiaomi_MI-C6-Grey  Mobiles & Tablets   \n",
       "347106            electro_Bluetooth Shower Speaker-Blue  Mobiles & Tablets   \n",
       "359740                            iPhone7Plus-Red-256GB  Mobiles & Tablets   \n",
       "363081                              infinix_Zero 4-Grey  Mobiles & Tablets   \n",
       "380977                      peekaboo_Batman-Black-2 Yrs        Kids & Baby   \n",
       "381035          peekaboo_Sun-Surf-&-Beach-Sando-2-years        Kids & Baby   \n",
       "381045  peekaboo_United-States-of-Awesome-Sando-2-years        Kids & Baby   \n",
       "395659                         sstop_samsungfastcharger  Mobiles & Tablets   \n",
       "397095                                  test-product-00                      \n",
       "401544                             yankee_5038500008357      Home & Living   \n",
       "401545                             yankee_5038500008357      Home & Living   \n",
       "401555                             yankee_5038580000269      Home & Living   \n",
       "401556                             yankee_5038580000269      Home & Living   \n",
       "\n",
       "                                              sku_and_cat  Customer ID  \\\n",
       "2649          AKL A131135338 FW 18 Orange Women's Fashion       5032.0   \n",
       "3528             AKL A131138782 SS 117 17 Women's Fashion       5032.0   \n",
       "3541             AKL A131138785 SS 119 17 Women's Fashion       5032.0   \n",
       "3548             AKL A131138786 SS 119 17 Women's Fashion       5032.0   \n",
       "3670             AKL A131138806 SS 130 17 Women's Fashion       5032.0   \n",
       "3676             AKL A131138807 SS 131 17 Women's Fashion       5032.0   \n",
       "8916                       APPDAW59FEF7B84F84B Appliances       5032.0   \n",
       "37338                          Anchor 439 L Men's Fashion       5032.0   \n",
       "37536                           Anchor 60 L Men's Fashion       5032.0   \n",
       "81826                      Delsey 207382001 Home & Living       5032.0   \n",
       "81853                  Delsey 8903338061328 Home & Living       5032.0   \n",
       "96301   Fashion Cafe kids Barcode 12738   12 18 mnths ...       5032.0   \n",
       "96312   Fashion Cafe kids Barcode 12745   12 18 mnths ...       5032.0   \n",
       "97480                     GA C 433 136144 Women's Fashion       5032.0   \n",
       "103755                        GS BS645 9 12 M Kids & Baby       5032.0   \n",
       "103759                        GS BS691 9 12 M Kids & Baby       5032.0   \n",
       "126151               IDROID BALRX7 Gold Mobiles & Tablets       5032.0   \n",
       "126561          IDROID BALRX7 Jet black Mobiles & Tablets       5032.0   \n",
       "131482  Infinix Note 3 2GB Nationwide Gold Mobiles & T...       5032.0   \n",
       "131596  Infinix Note 3 2GB Nationwide Grey Mobiles & T...       5032.0   \n",
       "167928              MATINF59C9002EA6AF0 Mobiles & Tablets       5032.0   \n",
       "171060              MATLEN5A000D63006BF Mobiles & Tablets       5032.0   \n",
       "172150              MATMOT59FC5E21CF296 Mobiles & Tablets       5032.0   \n",
       "173669              MATOPP59D1F6DC12873 Mobiles & Tablets       5032.0   \n",
       "197812                MEFBNB59FC74FDBC09F L Men's Fashion       5032.0   \n",
       "198098                MEFBNB59FC74FFCBC1B L Men's Fashion       5032.0   \n",
       "198303                MEFBNB59FC74FFCBC1B M Men's Fashion       5032.0   \n",
       "198868                MEFBNB59FC7507001A7 L Men's Fashion       5032.0   \n",
       "215698                MEFPAK5A094C054968C L Men's Fashion       5032.0   \n",
       "216439               MEFPAK5A094C0B66DD1 XL Men's Fashion       5032.0   \n",
       "231219                   NDF Channa Roasted 500gm Soghaat       5032.0   \n",
       "234220    Nimcos Black Pepper Potato Sticks 180gm Soghaat       5032.0   \n",
       "234349                  Nimcos Chilli Ringz 100gm Soghaat       5032.0   \n",
       "234705                   Nimcos Fried Onion 175gm Soghaat       5032.0   \n",
       "235039                   Nimcos Namak Paray 200gm Soghaat       5032.0   \n",
       "235243           Nimcos Potato Crisps Spicy 150gm Soghaat       5032.0   \n",
       "235278                 Nimcos Potato Sticks 150gm Soghaat       5032.0   \n",
       "235312              Nimcos Potato Sticks 350gm Superstore       5032.0   \n",
       "235617           Nimcos Spicy Potato Sticks 180gm Soghaat       5032.0   \n",
       "263521                           RS Coconut Bites Soghaat       5032.0   \n",
       "263522                           RS Coconut Bites Soghaat       5032.0   \n",
       "266495                               RS cake rusk Soghaat       5032.0   \n",
       "287957  Saylani Sehri and Iftari For One Person Per Da...       5032.0   \n",
       "290562                         Storline 30679 Kids & Baby       5032.0   \n",
       "290563                         Storline 30679 Kids & Baby       5032.0   \n",
       "294148         Telemall ASA Yechun Gloves Health & Sports       5032.0   \n",
       "327808             Xiaomi MI C6 Gold 64 Mobiles & Tablets       5032.0   \n",
       "327839                Xiaomi MI C6 Grey Mobiles & Tablets       5032.0   \n",
       "347106  electro Bluetooth Shower Speaker Blue Mobiles ...       5032.0   \n",
       "359740            iPhone7Plus Red 256GB Mobiles & Tablets       5032.0   \n",
       "363081              infinix Zero 4 Grey Mobiles & Tablets       5032.0   \n",
       "380977            peekaboo Batman Black 2 Yrs Kids & Baby       5032.0   \n",
       "381035  peekaboo Sun Surf & Beach Sando 2 years Kids &...       5032.0   \n",
       "381045  peekaboo United States of Awesome Sando 2 year...       5032.0   \n",
       "395659         sstop samsungfastcharger Mobiles & Tablets       5032.0   \n",
       "397095                                    test product 00       5032.0   \n",
       "401544                 yankee 5038500008357 Home & Living       5032.0   \n",
       "401545                 yankee 5038500008357 Home & Living       5032.0   \n",
       "401555                 yankee 5038580000269 Home & Living       5032.0   \n",
       "401556                 yankee 5038580000269 Home & Living       5032.0   \n",
       "\n",
       "           price  qty_ordered  invoice_amount  \n",
       "2649      2600.0          1.0          2600.0  \n",
       "3528      2400.0          1.0          2400.0  \n",
       "3541      2400.0          1.0          2400.0  \n",
       "3548      2400.0          1.0          2400.0  \n",
       "3670      2400.0          1.0          2400.0  \n",
       "3676      2400.0          1.0          2400.0  \n",
       "8916      9894.0          1.0          9894.0  \n",
       "37338      499.0          1.0           499.0  \n",
       "37536      549.0          1.0           549.0  \n",
       "81826    10656.0          1.0         10656.0  \n",
       "81853     2975.0          1.0          2975.0  \n",
       "96301      210.0          1.0           210.0  \n",
       "96312      210.0          1.0           210.0  \n",
       "97480     6000.0          1.0          6000.0  \n",
       "103755     695.0          1.0           695.0  \n",
       "103759     695.0          1.0           695.0  \n",
       "126151    8944.0       2000.0      17888000.0  \n",
       "126561    8944.0       2000.0      17888000.0  \n",
       "131482   18599.0          1.0         18599.0  \n",
       "131596   18599.0          1.0         18599.0  \n",
       "167928   12789.0          1.0         12789.0  \n",
       "171060    9799.0          3.0         29397.0  \n",
       "172150   13916.0          1.0         13916.0  \n",
       "173669   14948.0          1.0         14948.0  \n",
       "197812     249.0          2.0           498.0  \n",
       "198098     249.0          2.0           498.0  \n",
       "198303     249.0          1.0           249.0  \n",
       "198868     449.0          1.0           449.0  \n",
       "215698     699.0          1.0           699.0  \n",
       "216439     299.0          1.0           299.0  \n",
       "231219     215.0          1.0           215.0  \n",
       "234220     120.0          4.0           480.0  \n",
       "234349      90.0          1.0            90.0  \n",
       "234705     125.0          1.0           125.0  \n",
       "235039     110.0          1.0           110.0  \n",
       "235243     120.0          1.0           120.0  \n",
       "235278     110.0          1.0           110.0  \n",
       "235312     220.0          1.0           220.0  \n",
       "235617     120.0          1.0           120.0  \n",
       "263521     140.0          1.0           140.0  \n",
       "263522     145.0          1.0           145.0  \n",
       "266495     200.0          1.0           200.0  \n",
       "287957     160.0         15.0          2400.0  \n",
       "290562     745.0          2.0          1490.0  \n",
       "290563     995.0          1.0           995.0  \n",
       "294148     499.0          1.0           499.0  \n",
       "327808   25900.0          1.0         25900.0  \n",
       "327839   20900.0          1.0         20900.0  \n",
       "347106     499.0          1.0           499.0  \n",
       "359740  111856.0          1.0        111856.0  \n",
       "363081   22999.0          2.0         45998.0  \n",
       "380977     799.0          1.0           799.0  \n",
       "381035     299.0          1.0           299.0  \n",
       "381045     299.0          1.0           299.0  \n",
       "395659     750.0          1.0           750.0  \n",
       "397095       3.0          2.0             6.0  \n",
       "401544    2025.0         10.0         20250.0  \n",
       "401545    2700.0          5.0         13500.0  \n",
       "401555    2025.0          2.0          4050.0  \n",
       "401556    2700.0          1.0          2700.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transaction history of top spender.\n",
    "\n",
    "df[df[\"Customer ID\"]==5032].head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Trending Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:12:00.236406Z",
     "iopub.status.busy": "2021-10-26T07:12:00.236087Z",
     "iopub.status.idle": "2021-10-26T07:12:00.867722Z",
     "shell.execute_reply": "2021-10-26T07:12:00.866839Z",
     "shell.execute_reply.started": "2021-10-26T07:12:00.236366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>category_name_1</th>\n",
       "      <th>price</th>\n",
       "      <th>unique_customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATSAM59DB75ADB2F80</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>13698.0</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emart_00-7</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>699.0</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emart_00-1</td>\n",
       "      <td>Others</td>\n",
       "      <td>649.0</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unilever_Deal-6</td>\n",
       "      <td>Superstore</td>\n",
       "      <td>370.0</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al Muhafiz Sohan Halwa Almond</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>388.0</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101904</th>\n",
       "      <td>MEFSWA5A003FA7F2C7F</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101905</th>\n",
       "      <td>MEFSWA5A003FA56201C</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101906</th>\n",
       "      <td>MEFSWA5A003FA41FB65</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>9180.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101907</th>\n",
       "      <td>MEFSWA5A003FA049F8E</td>\n",
       "      <td>Men's Fashion</td>\n",
       "      <td>9180.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101908</th>\n",
       "      <td>20-herbal_Face Cleaner Lotion</td>\n",
       "      <td>Beauty &amp; Grooming</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sku    category_name_1    price  \\\n",
       "0                 MATSAM59DB75ADB2F80  Mobiles & Tablets  13698.0   \n",
       "1                          emart_00-7      Home & Living    699.0   \n",
       "2                          emart_00-1             Others    649.0   \n",
       "3                     unilever_Deal-6         Superstore    370.0   \n",
       "4       Al Muhafiz Sohan Halwa Almond            Soghaat    388.0   \n",
       "...                               ...                ...      ...   \n",
       "101904            MEFSWA5A003FA7F2C7F      Men's Fashion   5940.0   \n",
       "101905            MEFSWA5A003FA56201C      Men's Fashion   6600.0   \n",
       "101906            MEFSWA5A003FA41FB65      Men's Fashion   9180.0   \n",
       "101907            MEFSWA5A003FA049F8E      Men's Fashion   9180.0   \n",
       "101908  20-herbal_Face Cleaner Lotion  Beauty & Grooming   1312.0   \n",
       "\n",
       "        unique_customers  \n",
       "0                    652  \n",
       "1                    649  \n",
       "2                    601  \n",
       "3                    590  \n",
       "4                    580  \n",
       "...                  ...  \n",
       "101904                 1  \n",
       "101905                 1  \n",
       "101906                 1  \n",
       "101907                 1  \n",
       "101908                 1  \n",
       "\n",
       "[101909 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending = (\n",
    "        df.groupby([\"sku\", \"category_name_1\", \"price\"]).nunique()[\"Customer ID\"]\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html\n",
    "trending = trending.rename(columns={'Customer ID': 'unique_customers'})\n",
    "trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:12:10.801306Z",
     "iopub.status.busy": "2021-10-26T07:12:10.801013Z",
     "iopub.status.idle": "2021-10-26T07:12:10.806727Z",
     "shell.execute_reply": "2021-10-26T07:12:10.805882Z",
     "shell.execute_reply.started": "2021-10-26T07:12:10.801273Z"
    }
   },
   "outputs": [],
   "source": [
    "top_5_products = trending[\"sku\"].iloc[:5].values.tolist()\n",
    "top_5_prices = trending[\"price\"].iloc[:5].values.tolist()\n",
    "top_5_cat_name = trending[\"category_name_1\"].iloc[:5].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:12:15.056829Z",
     "iopub.status.busy": "2021-10-26T07:12:15.056210Z",
     "iopub.status.idle": "2021-10-26T07:12:15.090146Z",
     "shell.execute_reply": "2021-10-26T07:12:15.088910Z",
     "shell.execute_reply.started": "2021-10-26T07:12:15.056788Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>category_name_1</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>price</th>\n",
       "      <th>sku_and_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATSAM59DB75ADB2F80</td>\n",
       "      <td>Mobiles &amp; Tablets</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>13698.0</td>\n",
       "      <td>MATSAM59DB75ADB2F80 Mobiles &amp; Tablets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emart_00-7</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>emart_00-7 Home &amp; Living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emart_00-1</td>\n",
       "      <td>Others</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>emart_00-1 Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unilever_Deal-6</td>\n",
       "      <td>Superstore</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>unilever_Deal-6 Superstore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al Muhafiz Sohan Halwa Almond</td>\n",
       "      <td>Soghaat</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>Al Muhafiz Sohan Halwa Almond Soghaat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sku    category_name_1  Customer ID    price  \\\n",
       "0            MATSAM59DB75ADB2F80  Mobiles & Tablets       5032.0  13698.0   \n",
       "1                     emart_00-7      Home & Living       5032.0    699.0   \n",
       "2                     emart_00-1             Others       5032.0    649.0   \n",
       "3                unilever_Deal-6         Superstore       5032.0    370.0   \n",
       "4  Al Muhafiz Sohan Halwa Almond            Soghaat       5032.0    388.0   \n",
       "\n",
       "                             sku_and_cat  \n",
       "0  MATSAM59DB75ADB2F80 Mobiles & Tablets  \n",
       "1               emart_00-7 Home & Living  \n",
       "2                      emart_00-1 Others  \n",
       "3             unilever_Deal-6 Superstore  \n",
       "4  Al Muhafiz Sohan Halwa Almond Soghaat  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "        \"sku\": top_5_products,\n",
    "        \"category_name_1\": top_5_cat_name,\n",
    "        \"Customer ID\": top_spender,        \n",
    "        \"price\": top_5_prices,\n",
    "    }\n",
    "df_top_5 = pd.DataFrame(data)\n",
    "df_top_5[\"sku_and_cat\"] = df_top_5[\"sku\"] + \" \" + df_top_5[\"category_name_1\"]\n",
    "df_top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:12:41.067637Z",
     "iopub.status.busy": "2021-10-26T07:12:41.064999Z",
     "iopub.status.idle": "2021-10-26T07:12:41.365890Z",
     "shell.execute_reply": "2021-10-26T07:12:41.364401Z",
     "shell.execute_reply.started": "2021-10-26T07:12:41.067583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x200137 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(handle_unknown = \"ignore\")\n",
    "ohe_cols = [\"sku\", \"category_name_1\", \"Customer ID\"]\n",
    "ohe.fit(df[ohe_cols])\n",
    "ohe_features = ohe.transform(df_top_5[ohe_cols])\n",
    "ohe_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:12:47.459558Z",
     "iopub.status.busy": "2021-10-26T07:12:47.458462Z",
     "iopub.status.idle": "2021-10-26T07:12:48.871806Z",
     "shell.execute_reply": "2021-10-26T07:12:48.870917Z",
     "shell.execute_reply.started": "2021-10-26T07:12:47.459503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x10892 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sku_and_cat\"] = df[\"sku_and_cat\"].str.replace(\"-\", \" \")\n",
    "df[\"sku_and_cat\"] = df[\"sku_and_cat\"].str.replace(\"_\", \" \")\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=2)  # Ignore terms that appear in less than 2 documents.\n",
    "vectorizer.fit(df[\"sku_and_cat\"].unique())\n",
    "tfidf_features = vectorizer.transform(df_top_5[\"sku_and_cat\"])\n",
    "tfidf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:12:56.582580Z",
     "iopub.status.busy": "2021-10-26T07:12:56.582231Z",
     "iopub.status.idle": "2021-10-26T07:12:56.593279Z",
     "shell.execute_reply": "2021-10-26T07:12:56.592581Z",
     "shell.execute_reply.started": "2021-10-26T07:12:56.582544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x1 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = range(len(df_top_5))\n",
    "col = [0] * len(df_top_5)   # This is a list of zeros [0,0,0,....]\n",
    "price = csr_matrix((df_top_5[\"price\"].values, (row, col)), dtype=\"float32\")\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:12:59.344411Z",
     "iopub.status.busy": "2021-10-26T07:12:59.343545Z",
     "iopub.status.idle": "2021-10-26T07:12:59.354235Z",
     "shell.execute_reply": "2021-10-26T07:12:59.353490Z",
     "shell.execute_reply.started": "2021-10-26T07:12:59.344357Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x211030 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 32 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_top_5 = hstack([ohe_features, tfidf_features, price], format=\"csr\", dtype=\"float32\")\n",
    "X_top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T07:13:01.909975Z",
     "iopub.status.busy": "2021-10-26T07:13:01.909458Z",
     "iopub.status.idle": "2021-10-26T07:13:01.919048Z",
     "shell.execute_reply": "2021-10-26T07:13:01.917958Z",
     "shell.execute_reply.started": "2021-10-26T07:13:01.909939Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.,     0.,     0., ...,     0.,     0., 13698.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0.,   699.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0.,   649.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0.,   370.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0.,   388.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_top_5.toarray()\n",
    "# pd.DataFrame(X_top_5.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recommendation for top spender from the top 5 trending products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.187561Z",
     "iopub.status.idle": "2021-10-26T06:56:30.188049Z",
     "shell.execute_reply": "2021-10-26T06:56:30.187826Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.187798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 33.07421875},\n",
       "  {'score': 5.309963226318359},\n",
       "  {'score': 6.309589385986328},\n",
       "  {'score': 4.952110290527344},\n",
       "  {'score': 4.305643081665039}]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predictor.predict(X_top_5.toarray())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.190382Z",
     "iopub.status.idle": "2021-10-26T06:56:30.190880Z",
     "shell.execute_reply": "2021-10-26T06:56:30.190628Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.190604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33.07421875,\n",
       " 5.309963226318359,\n",
       " 6.309589385986328,\n",
       " 4.952110290527344,\n",
       " 4.305643081665039]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [i[\"score\"] for i in result[\"predictions\"]]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.193083Z",
     "iopub.status.idle": "2021-10-26T06:56:30.193526Z",
     "shell.execute_reply": "2021-10-26T06:56:30.193309Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.193287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 1, 2, 0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argsort: smaller values are in front, bigger values are behind.\n",
    "\n",
    "index_array = np.array(predictions).argsort()\n",
    "index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.198292Z",
     "iopub.status.idle": "2021-10-26T06:56:30.198824Z",
     "shell.execute_reply": "2021-10-26T06:56:30.198550Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.198525Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MATSAM59DB75ADB2F80', 'emart_00-7', 'emart_00-1',\n",
       "       'unilever_Deal-6', 'Al Muhafiz Sohan Halwa Almond'], dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skus = ohe.inverse_transform(ohe_features)[:, 0]\n",
    "skus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 recommendations for top spender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-26T06:56:30.200547Z",
     "iopub.status.idle": "2021-10-26T06:56:30.201040Z",
     "shell.execute_reply": "2021-10-26T06:56:30.200850Z",
     "shell.execute_reply.started": "2021-10-26T06:56:30.200827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MATSAM59DB75ADB2F80', 'emart_00-1', 'emart_00-7'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 3 recommendations means take the biggest values from behind \n",
    "# (i.e. index 0 followed by index 2 and 1).\n",
    "\n",
    "top_3_recommended = np.take_along_axis(skus, index_array, axis=0)[: -3 - 1 : -1]\n",
    "top_3_recommended"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
